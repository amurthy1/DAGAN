{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import slim\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.ones((1, 100)) * 0.5#np.random.randn(1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = np.load(\"datasets/omniglot_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = np.ones((1, 28, 28, 1))\n",
    "inp = np.array([raw_data[1200][0]], dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dagan_architectures import UResNetGenerator, Discriminator\n",
    "\n",
    "g = UResNetGenerator(batch_size=1, layer_sizes=[64, 64, 128, 128], layer_padding=None,\n",
    "                        inner_layers=[3] * 4, name=\"generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_inp = tf.placeholder(tf.float32, [1,100], 'z-inp')\n",
    "cond_inp = tf.placeholder(tf.float32, [1,28,28,1], 'cond-inp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1, 2, 2, 128]\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_1/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_1/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_1/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "\n",
      "\n",
      "1 [1, 4, 4, 128]\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/conv2d_transpose/BiasAdd:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/conv2d_transpose_1/BiasAdd:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm_1/batchnorm/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm_1/batchnorm/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/conv2d_transpose_2/BiasAdd:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm_1/batchnorm/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "\n",
      "\n",
      "2 [1, 7, 7, 64]\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_2:0\", shape=(1, 7, 7, 194), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_2:0\", shape=(1, 7, 7, 194), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_2:0\", shape=(1, 7, 7, 194), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/conv2d_transpose/BiasAdd:0\", shape=(1, 7, 7, 128), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 7, 7, 64), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_2:0\", shape=(1, 7, 7, 194), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/conv2d_transpose_1/BiasAdd:0\", shape=(1, 7, 7, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_2:0\", shape=(1, 7, 7, 194), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/BatchNorm_1/batchnorm/add_1:0\", shape=(1, 7, 7, 64), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_2:0\", shape=(1, 7, 7, 194), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/BatchNorm_1/batchnorm/add_1:0\", shape=(1, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/conv2d_transpose_2/BiasAdd:0\", shape=(1, 7, 7, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_2:0\", shape=(1, 7, 7, 194), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 7, 7, 64), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 7, 7, 64), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_2:0\", shape=(1, 7, 7, 194), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 7, 7, 64), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_2:0\", shape=(1, 7, 7, 194), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/BatchNorm_1/batchnorm/add_1:0\", shape=(1, 7, 7, 64), dtype=float32)\n",
      "\n",
      "\n",
      "3 [1, 14, 14, 64]\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/concat_4:0\", shape=(1, 14, 14, 128), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_2:0\", shape=(1, 7, 7, 194), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/concat_4:0\", shape=(1, 14, 14, 128), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/concat_4:0\", shape=(1, 14, 14, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/conv2d_transpose/BiasAdd:0\", shape=(1, 14, 14, 64), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 14, 14, 64), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_2:0\", shape=(1, 7, 7, 194), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/concat_4:0\", shape=(1, 14, 14, 128), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/conv2d_transpose_1/BiasAdd:0\", shape=(1, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/concat_4:0\", shape=(1, 14, 14, 128), dtype=float32)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/BatchNorm_1/batchnorm/add_1:0\", shape=(1, 14, 14, 64), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_2:0\", shape=(1, 7, 7, 194), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/concat_4:0\", shape=(1, 14, 14, 128), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/BatchNorm_1/batchnorm/add_1:0\", shape=(1, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/conv2d_transpose_2/BiasAdd:0\", shape=(1, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/concat_4:0\", shape=(1, 14, 14, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 14, 14, 64), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 14, 14, 64), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_2:0\", shape=(1, 7, 7, 194), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/concat_4:0\", shape=(1, 14, 14, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 14, 14, 64), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/concat_4:0\", shape=(1, 14, 14, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/BatchNorm_1/batchnorm/add_1:0\", shape=(1, 14, 14, 64), dtype=float32)\n",
      "\n",
      "\n",
      "4 [1, 28, 28, 1]\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_3:0\", shape=(1, 28, 28, 65), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_2:0\", shape=(1, 7, 7, 194), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/concat_4:0\", shape=(1, 14, 14, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/dropout/Identity:0\", shape=(1, 28, 28, 64), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_3:0\", shape=(1, 28, 28, 65), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv4/conv2d_transpose/BiasAdd:0\", shape=(1, 28, 28, 64), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv4/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 28, 28, 64), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_2:0\", shape=(1, 7, 7, 194), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/concat_4:0\", shape=(1, 14, 14, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/dropout/Identity:0\", shape=(1, 28, 28, 64), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv4/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 28, 28, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv4/conv2d_transpose_1/BiasAdd:0\", shape=(1, 28, 28, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_3:0\", shape=(1, 28, 28, 65), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv4/BatchNorm_1/batchnorm/add_1:0\", shape=(1, 28, 28, 64), dtype=float32)\n",
      "Current Layers\n",
      "Tensor(\"generator_9/g_deconv_layers/concat:0\", shape=(1, 2, 2, 136), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv0/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 2, 2, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_1:0\", shape=(1, 4, 4, 260), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv1/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_2:0\", shape=(1, 7, 7, 194), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv2/concat_4:0\", shape=(1, 14, 14, 128), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/BatchNorm_2/batchnorm/add_1:0\", shape=(1, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv3/dropout/Identity:0\", shape=(1, 28, 28, 64), dtype=float32)\n",
      "\n",
      "\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv4/BatchNorm_1/batchnorm/add_1:0\", shape=(1, 28, 28, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv4/conv2d_transpose_2/BiasAdd:0\", shape=(1, 28, 28, 64), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/concat_3:0\", shape=(1, 28, 28, 65), dtype=float32)\n",
      "Tensor(\"generator_9/g_deconv_layers/g_deconv4/BatchNorm/batchnorm_1/add_1:0\", shape=(1, 28, 28, 64), dtype=float32)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = g(z_inp, cond_inp, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/checkpoint.ckpt\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"checkpoints/checkpoint.ckpt\"\n",
    "fine_tune = slim.assign_from_checkpoint_fn(\n",
    "    checkpoint,\n",
    "    tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES))\n",
    "\n",
    "sess = tf.Session()\n",
    "fine_tune(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989437"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results = sess.run(\n",
    "    result,\n",
    "    feed_dict={z_inp: z, cond_inp: inp},\n",
    ")\n",
    "final_results[0][0, :, :, 0][5][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _SamePad(nn.Module):\n",
    "    \"\"\"\n",
    "    Pads equivalent to the behavior of tensorflow \"SAME\"\n",
    "    \"\"\"\n",
    "    def __init__(self, stride):\n",
    "        super().__init__()\n",
    "        self.stride = stride\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.stride == 2 and x.shape[2] % 2 == 0:\n",
    "            return F.pad(x, (0, 1, 0, 1))\n",
    "        return F.pad(x, (1, 1, 1, 1))\n",
    "\n",
    "def _conv2d(in_channels, out_channels, kernel_size, stride, activate=True, dropout=0.0):\n",
    "    layers = OrderedDict()\n",
    "    layers['pad'] = _SamePad(stride)\n",
    "    layers['conv'] = nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "    if activate:\n",
    "        layers['relu'] = nn.LeakyReLU(0.2)\n",
    "        layers['batchnorm'] = nn.BatchNorm2d(out_channels, eps=1e-3, momentum=0.01)\n",
    "    \n",
    "    if dropout > 0.0:\n",
    "        layers['dropout'] = nn.Dropout(dropout)\n",
    "    return nn.Sequential(layers)\n",
    "\n",
    "\n",
    "def _conv2d_transpose(in_channels, out_channels, kernel_size, upscale_size, activate=True, dropout=0.0):\n",
    "    layers = OrderedDict()\n",
    "    layers['upsample'] = nn.Upsample(upscale_size)\n",
    "    layers['conv'] = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=1)\n",
    "    if activate:\n",
    "        layers['relu'] = nn.LeakyReLU(0.2)\n",
    "        layers['batchnorm'] = nn.BatchNorm2d(out_channels, eps=1e-3, momentum=0.01)\n",
    "    \n",
    "    if dropout > 0.0:\n",
    "        layers['dropout'] = nn.Dropout(dropout)\n",
    "    return nn.Sequential(layers)\n",
    "\n",
    "\n",
    "class _EncoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, pre_channels, in_channels, out_channels, num_layers, dropout_rate=0.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.pre_conv = _conv2d(\n",
    "            in_channels=pre_channels, out_channels=pre_channels, kernel_size=3, stride=2, activate=False\n",
    "        )\n",
    "\n",
    "        self.conv0 = _conv2d(\n",
    "            in_channels=in_channels + pre_channels, out_channels=out_channels, kernel_size=3, stride=1\n",
    "        )\n",
    "        total_channels = in_channels + out_channels\n",
    "        for i in range(1, num_layers):\n",
    "            self.add_module(\n",
    "                'conv%d' % i,\n",
    "                _conv2d(\n",
    "                    in_channels=total_channels, out_channels=out_channels, kernel_size=3, stride=1\n",
    "                )\n",
    "            )\n",
    "            total_channels += out_channels\n",
    "        self.add_module(\n",
    "            'conv%d' % num_layers,\n",
    "            _conv2d(\n",
    "                in_channels=total_channels, out_channels=out_channels, kernel_size=3, stride=2, dropout=dropout_rate\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        pre_input, x = inp\n",
    "        pre_input = self.pre_conv(pre_input)\n",
    "        out = self.conv0(torch.cat([x, pre_input], 1))\n",
    "        \n",
    "        all_outputs = [x, out]\n",
    "        for i in range(1, self.num_layers + 1):\n",
    "            input_features = torch.cat([all_outputs[-1], all_outputs[-2]] + all_outputs[:-2], 1)\n",
    "            module = self._modules['conv%d' % i]\n",
    "            out = module(input_features)\n",
    "            all_outputs.append(out)\n",
    "        return all_outputs[-2], all_outputs[-1]\n",
    "\n",
    "    \n",
    "class _DecoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, pre_channels, in_channels, out_channels, num_layers, curr_size, upscale_size=None, dropout_rate=0.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.should_upscale = upscale_size is not None\n",
    "        self.should_pre_conv = pre_channels > 0\n",
    "#         self.pre_conv = _conv2d(\n",
    "#             in_channels=pre_channels, out_channels=pre_channels, kernel_size=3, stride=2, activate=False\n",
    "#         )\n",
    "\n",
    "#         self.conv0 = _conv2d(\n",
    "#             in_channels=in_channels + pre_channels, out_channels=out_channels, kernel_size=3, stride=1\n",
    "#         )\n",
    "\n",
    "        total_channels = pre_channels + in_channels\n",
    "        for i in range(num_layers):\n",
    "            if self.should_pre_conv:\n",
    "                self.add_module(\n",
    "                    'pre_conv_t%d' % i,\n",
    "                    _conv2d_transpose(\n",
    "                        in_channels=pre_channels, out_channels=pre_channels,\n",
    "                        kernel_size=3, upscale_size=curr_size, activate=False\n",
    "                    )\n",
    "                )\n",
    "            self.add_module(\n",
    "                'conv%d' % i,\n",
    "                _conv2d(\n",
    "                    in_channels=total_channels, out_channels=out_channels, kernel_size=3, stride=1\n",
    "                )\n",
    "            )\n",
    "            total_channels += out_channels\n",
    "\n",
    "        if self.should_upscale:\n",
    "            total_channels -= pre_channels\n",
    "            self.add_module(\n",
    "                'conv_t%d' % num_layers,\n",
    "                _conv2d_transpose(\n",
    "                    in_channels=total_channels, out_channels=out_channels,\n",
    "                    kernel_size=3, upscale_size=upscale_size, dropout=dropout_rate\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        pre_input, x = inp\n",
    "#         pre_input = self.pre_conv(pre_input)\n",
    "#         out = self.conv0(torch.cat([x, pre_input], 1))\n",
    "#         print(pre_input.shape, x.shape)\n",
    "        all_outputs = [x]\n",
    "        for i in range(self.num_layers):\n",
    "            curr_input = all_outputs[-1]\n",
    "            if self.should_pre_conv:\n",
    "                pre_conv_output = self._modules['pre_conv_t%d' % i](pre_input)\n",
    "                curr_input = torch.cat([curr_input, pre_conv_output], 1)\n",
    "            input_features = torch.cat([curr_input] + all_outputs[:-1], 1)\n",
    "            module = self._modules['conv%d' % i]\n",
    "            out = module(input_features)\n",
    "            all_outputs.append(out)\n",
    "\n",
    "        if self.should_upscale:\n",
    "            module = self._modules['conv_t%d' % self.num_layers]\n",
    "            input_features = torch.cat([all_outputs[-1], all_outputs[0]] + all_outputs[1:-1], 1)\n",
    "            out = module(input_features)\n",
    "            all_outputs.append(out)\n",
    "        return all_outputs[-2], all_outputs[-1]\n",
    "\n",
    "\n",
    "class TorchGAN(nn.Module):\n",
    "    def __init__(self, dim, channels, dropout_rate=0.0, z_dim=100):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.z_dim = z_dim\n",
    "        self.channels = channels\n",
    "        self.layer_sizes = [64, 64, 128, 128]\n",
    "        self.num_inner_layers = 3\n",
    "\n",
    "        # Number of times dimension is halved\n",
    "        self.U_depth = len(self.layer_sizes)\n",
    "        \n",
    "        # dimension at each level of U-net\n",
    "        self.dim_arr = [dim]\n",
    "        for i in range(self.U_depth):\n",
    "            self.dim_arr.append((self.dim_arr[-1] + 1) // 2)\n",
    "        \n",
    "        # Encoders\n",
    "        self.encode0 = _conv2d(\n",
    "            in_channels=1, out_channels=self.layer_sizes[0], kernel_size=3, stride=2\n",
    "        )\n",
    "        for i in range(1, self.U_depth):\n",
    "            self.add_module(\n",
    "                \"encode%d\" % i,\n",
    "                _EncoderBlock(\n",
    "                    pre_channels=self.layer_sizes[i - 1],\n",
    "                    in_channels=self.layer_sizes[i - 1],\n",
    "                    out_channels=self.layer_sizes[i],\n",
    "                    num_layers=self.num_inner_layers,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Noise encoders\n",
    "        self.noise_encoders = 3\n",
    "        num_noise_filters = 8\n",
    "        self.z_channels = []\n",
    "        for i in range(self.noise_encoders):\n",
    "            curr_dim = self.dim_arr[-1 - i]  # Iterate dim from back\n",
    "            self.add_module(\n",
    "                \"z_reshape%d\" % i,\n",
    "                nn.Linear(self.z_dim, curr_dim * curr_dim * num_noise_filters)\n",
    "            )\n",
    "            self.z_channels.append(num_noise_filters)\n",
    "            num_noise_filters //= 2\n",
    "            \n",
    "        # Decoders\n",
    "        for i in range(self.U_depth + 1):\n",
    "            # Input from previous decoder\n",
    "            in_channels = 0 if i == 0 else self.layer_sizes[-i]\n",
    "            # Input from encoder across the \"U\"\n",
    "            in_channels += self.channels if i == self.U_depth else self.layer_sizes[-i - 1]\n",
    "            # Input from injected noise\n",
    "            if i < self.noise_encoders:\n",
    "                in_channels += self.z_channels[i]\n",
    "\n",
    "            self.add_module(\n",
    "                \"decode%d\" % i,\n",
    "                _DecoderBlock(\n",
    "                    pre_channels=0 if i == 0 else self.layer_sizes[-i],\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=self.layer_sizes[0] if i == self.U_depth else self.layer_sizes[-i - 1],\n",
    "                    num_layers=self.num_inner_layers,\n",
    "                    curr_size=self.dim_arr[-i - 1],\n",
    "                    upscale_size=None if i == self.U_depth else self.dim_arr[-i - 2],\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Final conv\n",
    "        self.num_final_conv = 3\n",
    "        for i in range(self.num_final_conv - 1):\n",
    "            self.add_module(\n",
    "                \"final_conv%d\" % i,\n",
    "                _conv2d(\n",
    "                    in_channels=self.layer_sizes[0], out_channels=self.layer_sizes[0], kernel_size=3, stride=1\n",
    "                )\n",
    "            )\n",
    "        self.add_module(\n",
    "            \"final_conv%d\" % (self.num_final_conv - 1),\n",
    "            _conv2d(\n",
    "                in_channels=self.layer_sizes[0], out_channels=self.channels, kernel_size=3, stride=1, activate=False\n",
    "            )\n",
    "        )\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        # Final output of every encoding block\n",
    "        all_outputs = [x, self.encode0(x)]\n",
    "\n",
    "        # Last 2 layer outputs\n",
    "        out = [x, self.encode0(x)]\n",
    "        for i in range(1, len(self.layer_sizes)):\n",
    "            out = self._modules[\"encode%d\" % i](out)\n",
    "            all_outputs.append(out[1])\n",
    "        \n",
    "        print(out[1][0][0])\n",
    "        pre_input, curr_input = None, out[1]\n",
    "        for i in range(self.U_depth + 1):\n",
    "            if i > 0:\n",
    "                curr_input = torch.cat([curr_input, all_outputs[-i - 1]], 1)\n",
    "            if i < self.noise_encoders:\n",
    "                z_out = self._modules[\"z_reshape%d\" % i](z)\n",
    "                \n",
    "                # TODO remove transform when removing tf dependency\n",
    "                curr_dim = self.dim_arr[-i - 1]\n",
    "                z_out = z_out.view(-1, curr_dim, curr_dim, self.z_channels[i])\n",
    "                z_out = z_out.transpose(1, 3).transpose(2, 3)\n",
    "                curr_input = torch.cat([z_out, curr_input], 1)\n",
    "            \n",
    "            pre_input, curr_input = self._modules[\"decode%d\" % i]([pre_input, curr_input])\n",
    "        \n",
    "        print(curr_input[0][0][0])\n",
    "        for i in range(self.num_final_conv):\n",
    "            curr_input = self._modules[\"final_conv%d\" % i](curr_input)\n",
    "        return self.tanh(curr_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchGAN(\n",
       "  (encode0): Sequential(\n",
       "    (pad): _SamePad()\n",
       "    (conv): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (relu): LeakyReLU(negative_slope=0.2)\n",
       "    (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (encode1): _EncoderBlock(\n",
       "    (pre_conv): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    )\n",
       "    (conv0): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (encode2): _EncoderBlock(\n",
       "    (pre_conv): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    )\n",
       "    (conv0): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(320, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(448, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (encode3): _EncoderBlock(\n",
       "    (pre_conv): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    )\n",
       "    (conv0): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (z_reshape0): Linear(in_features=100, out_features=32, bias=True)\n",
       "  (z_reshape1): Linear(in_features=100, out_features=64, bias=True)\n",
       "  (z_reshape2): Linear(in_features=100, out_features=98, bias=True)\n",
       "  (decode0): _DecoderBlock(\n",
       "    (conv0): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(136, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(264, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(392, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_t3): Sequential(\n",
       "      (upsample): Upsample(size=4, mode=nearest)\n",
       "      (conv): ConvTranspose2d(520, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (decode1): _DecoderBlock(\n",
       "    (pre_conv_t0): Sequential(\n",
       "      (upsample): Upsample(size=4, mode=nearest)\n",
       "      (conv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv0): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(388, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pre_conv_t1): Sequential(\n",
       "      (upsample): Upsample(size=4, mode=nearest)\n",
       "      (conv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(516, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pre_conv_t2): Sequential(\n",
       "      (upsample): Upsample(size=4, mode=nearest)\n",
       "      (conv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(644, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_t3): Sequential(\n",
       "      (upsample): Upsample(size=7, mode=nearest)\n",
       "      (conv): ConvTranspose2d(644, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (decode2): _DecoderBlock(\n",
       "    (pre_conv_t0): Sequential(\n",
       "      (upsample): Upsample(size=7, mode=nearest)\n",
       "      (conv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv0): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(322, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pre_conv_t1): Sequential(\n",
       "      (upsample): Upsample(size=7, mode=nearest)\n",
       "      (conv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(386, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pre_conv_t2): Sequential(\n",
       "      (upsample): Upsample(size=7, mode=nearest)\n",
       "      (conv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(450, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_t3): Sequential(\n",
       "      (upsample): Upsample(size=14, mode=nearest)\n",
       "      (conv): ConvTranspose2d(386, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (decode3): _DecoderBlock(\n",
       "    (pre_conv_t0): Sequential(\n",
       "      (upsample): Upsample(size=14, mode=nearest)\n",
       "      (conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv0): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pre_conv_t1): Sequential(\n",
       "      (upsample): Upsample(size=14, mode=nearest)\n",
       "      (conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pre_conv_t2): Sequential(\n",
       "      (upsample): Upsample(size=14, mode=nearest)\n",
       "      (conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_t3): Sequential(\n",
       "      (upsample): Upsample(size=28, mode=nearest)\n",
       "      (conv): ConvTranspose2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (decode4): _DecoderBlock(\n",
       "    (pre_conv_t0): Sequential(\n",
       "      (upsample): Upsample(size=28, mode=nearest)\n",
       "      (conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv0): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(129, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pre_conv_t1): Sequential(\n",
       "      (upsample): Upsample(size=28, mode=nearest)\n",
       "      (conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(193, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pre_conv_t2): Sequential(\n",
       "      (upsample): Upsample(size=28, mode=nearest)\n",
       "      (conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(257, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (final_conv0): Sequential(\n",
       "    (pad): _SamePad()\n",
       "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (relu): LeakyReLU(negative_slope=0.2)\n",
       "    (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (final_conv1): Sequential(\n",
       "    (pad): _SamePad()\n",
       "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (relu): LeakyReLU(negative_slope=0.2)\n",
       "    (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (final_conv2): Sequential(\n",
       "    (pad): _SamePad()\n",
       "    (conv): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_g = TorchGAN(dim=28, channels=1)\n",
    "torch_g.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_reader = tf.train.load_checkpoint(checkpoint)\n",
    "def read_tf(var):\n",
    "    return torch.tensor(ckpt_reader.get_tensor(var))\n",
    "\n",
    "def reshape_conv(tensor):\n",
    "    return tensor.transpose(0, 3).transpose(1, 2).transpose(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_conv_layer(torch_layer, conv_path, bn_path=None):\n",
    "    if bn_path is not None:\n",
    "        torch_layer.batchnorm.weight.data = read_tf(bn_path + \"/gamma\")\n",
    "        torch_layer.batchnorm.bias.data = read_tf(bn_path + \"/beta\")\n",
    "        torch_layer.batchnorm.running_mean = read_tf(bn_path + \"/moving_mean\")\n",
    "        torch_layer.batchnorm.running_var = read_tf(bn_path + \"/moving_variance\")\n",
    "    \n",
    "    torch_layer.conv.weight.data = reshape_conv(read_tf(conv_path + \"/kernel\"))\n",
    "    torch_layer.conv.bias.data = read_tf(conv_path + \"/bias\")\n",
    "    \n",
    "num_layers = torch_g.num_inner_layers\n",
    "\n",
    "# Encoders\n",
    "convert_conv_layer(\n",
    "    torch_g.encode0, \"generator/conv_layers/g_conv0/conv2d\", \"generator/conv_layers/g_conv0/BatchNorm\")\n",
    "\n",
    "for i in range(1, torch_g.U_depth):\n",
    "    module = torch_g._modules[\"encode%d\" % i]\n",
    "    convert_conv_layer(\n",
    "        module.pre_conv,\n",
    "        f\"generator/conv_layers/g_conv{i}/conv2d\"\n",
    "    )\n",
    "\n",
    "    for j in range(num_layers + 1):\n",
    "        bn_suffix = f\"_{j}\" if j > 0 else \"\"\n",
    "        convert_conv_layer(\n",
    "            module._modules[f\"conv{j}\"],\n",
    "            f\"generator/conv_layers/g_conv{i}/conv2d_{j + 1}\",\n",
    "            f\"generator/conv_layers/g_conv{i}/BatchNorm{bn_suffix}\",\n",
    "        )\n",
    "\n",
    "# Noise encoders\n",
    "for i in range(torch_g.noise_encoders):\n",
    "    module = torch_g._modules[\"z_reshape%d\" % i]\n",
    "    z_suffix = f\"_{i}\" if i > 0 else \"\"\n",
    "    module.weight.data = read_tf(f\"generator/vector_expansion/dense{z_suffix}/kernel\").T\n",
    "    module.bias.data = read_tf(f\"generator/vector_expansion/dense{z_suffix}/bias\").T\n",
    "\n",
    "\n",
    "# Decoders\n",
    "for i in range(torch_g.U_depth + 1):\n",
    "    module = torch_g._modules[\"decode%d\" % i]\n",
    "\n",
    "    for j in range(num_layers):\n",
    "        idx_suffix = f\"_{j}\" if j > 0 else \"\"\n",
    "        if i > 0:\n",
    "            convert_conv_layer(\n",
    "                module._modules[f\"pre_conv_t{j}\"],\n",
    "                f\"generator/g_deconv_layers/g_deconv{i}/conv2d_transpose{idx_suffix}\",\n",
    "            )\n",
    "        convert_conv_layer(\n",
    "            module._modules[f\"conv{j}\"],\n",
    "            f\"generator/g_deconv_layers/g_deconv{i}/conv2d{idx_suffix}\",\n",
    "            f\"generator/g_deconv_layers/g_deconv{i}/BatchNorm{idx_suffix}\",\n",
    "        )\n",
    "    if i < torch_g.U_depth:\n",
    "        conv_suffix = f\"_{num_layers}\" if i > 0 else \"\"\n",
    "        convert_conv_layer(\n",
    "            module._modules[f\"conv_t{num_layers}\"],\n",
    "            f\"generator/g_deconv_layers/g_deconv{i}/conv2d_transpose{conv_suffix}\",\n",
    "            f\"generator/g_deconv_layers/g_deconv{i}/BatchNorm_{num_layers}\",\n",
    "        )\n",
    "        \n",
    "# Final conv\n",
    "for i in range(torch_g.num_final_conv):\n",
    "    idx_suffix = f\"_{i}\" if i > 0 else \"\"\n",
    "    if i == torch_g.num_final_conv - 1:\n",
    "        bn_path = None\n",
    "    else:\n",
    "        bn_path = f\"generator/g_deconv_layers/BatchNorm{idx_suffix}\"\n",
    "    convert_conv_layer(\n",
    "        torch_g._modules[f\"final_conv{i}\"],\n",
    "        f\"generator/g_deconv_layers/conv2d{idx_suffix}\",\n",
    "        bn_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_tf(f\"generator/vector_expansion/dense/kernel\").T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28, 1])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(inp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5892, -0.4865],\n",
      "        [ 0.5238, -0.4740]], grad_fn=<SelectBackward>)\n",
      "tensor([ 0.0840, -0.0228, -0.0525, -0.0474, -0.0420, -0.0397, -0.0376, -0.0234,\n",
      "        -0.0068,  0.0021, -0.0040, -0.0167, -0.0205, -0.0231, -0.0167, -0.0158,\n",
      "         0.0006,  0.0117,  0.0174,  0.0188,  0.0079, -0.0050, -0.0161, -0.0455,\n",
      "        -0.0516, -0.0863, -0.0326,  0.0853], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.9968, 0.9989, 0.9986, 0.9990, 0.9992, 0.9993, 0.9992, 0.9992, 0.9992,\n",
       "        0.9992, 0.9992, 0.9992, 0.9992, 0.9991, 0.9990, 0.9989, 0.9990, 0.9990,\n",
       "        0.9991, 0.9992, 0.9993, 0.9994, 0.9994, 0.9994, 0.9993, 0.9992, 0.9996,\n",
       "        0.9983], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum(sum(torch_g.conv.weight[0][0]))\n",
    "# print(torch_g(torch.ones(1, 1, 28, 28)).shape)\n",
    "# torch_inp = torch.ones(1, 1, 28, 28)\n",
    "torch_inp = torch.tensor(inp).transpose(1, 3).transpose(2, 3).float()\n",
    "torch_g(torch_inp, torch.tensor(z).float())[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.9968462 ],\n",
       "         [ 0.9989222 ],\n",
       "         [ 0.99855083],\n",
       "         [ 0.9990234 ],\n",
       "         [ 0.99923205],\n",
       "         [ 0.99925864],\n",
       "         [ 0.999233  ],\n",
       "         [ 0.99920547],\n",
       "         [ 0.99920064],\n",
       "         [ 0.99921155],\n",
       "         [ 0.99922633],\n",
       "         [ 0.9992216 ],\n",
       "         [ 0.9991688 ],\n",
       "         [ 0.99908626],\n",
       "         [ 0.9989827 ],\n",
       "         [ 0.9989365 ],\n",
       "         [ 0.99896497],\n",
       "         [ 0.99904543],\n",
       "         [ 0.9991413 ],\n",
       "         [ 0.99921304],\n",
       "         [ 0.9992914 ],\n",
       "         [ 0.99936825],\n",
       "         [ 0.9993983 ],\n",
       "         [ 0.999387  ],\n",
       "         [ 0.99926925],\n",
       "         [ 0.99922645],\n",
       "         [ 0.9995618 ],\n",
       "         [ 0.9982861 ]],\n",
       "\n",
       "        [[ 0.99911857],\n",
       "         [ 0.9995758 ],\n",
       "         [ 0.9996732 ],\n",
       "         [ 0.99970555],\n",
       "         [ 0.9996501 ],\n",
       "         [ 0.9996456 ],\n",
       "         [ 0.9996344 ],\n",
       "         [ 0.9996166 ],\n",
       "         [ 0.99958926],\n",
       "         [ 0.9996042 ],\n",
       "         [ 0.99962914],\n",
       "         [ 0.99967337],\n",
       "         [ 0.9996983 ],\n",
       "         [ 0.9996926 ],\n",
       "         [ 0.9996852 ],\n",
       "         [ 0.99968594],\n",
       "         [ 0.99969023],\n",
       "         [ 0.99969697],\n",
       "         [ 0.9996909 ],\n",
       "         [ 0.9996857 ],\n",
       "         [ 0.9996923 ],\n",
       "         [ 0.99971974],\n",
       "         [ 0.99974966],\n",
       "         [ 0.99978775],\n",
       "         [ 0.99978715],\n",
       "         [ 0.99982905],\n",
       "         [ 0.99992347],\n",
       "         [ 0.9998011 ]],\n",
       "\n",
       "        [[ 0.9993862 ],\n",
       "         [ 0.99944896],\n",
       "         [ 0.99918836],\n",
       "         [ 0.99899143],\n",
       "         [ 0.99894613],\n",
       "         [ 0.99890906],\n",
       "         [ 0.99880457],\n",
       "         [ 0.99873894],\n",
       "         [ 0.9987251 ],\n",
       "         [ 0.998823  ],\n",
       "         [ 0.9988968 ],\n",
       "         [ 0.99900997],\n",
       "         [ 0.9991081 ],\n",
       "         [ 0.9991452 ],\n",
       "         [ 0.999161  ],\n",
       "         [ 0.9991909 ],\n",
       "         [ 0.99917287],\n",
       "         [ 0.99916136],\n",
       "         [ 0.9991371 ],\n",
       "         [ 0.9990975 ],\n",
       "         [ 0.9990503 ],\n",
       "         [ 0.9990917 ],\n",
       "         [ 0.9991522 ],\n",
       "         [ 0.99928904],\n",
       "         [ 0.99924606],\n",
       "         [ 0.99940264],\n",
       "         [ 0.99987525],\n",
       "         [ 0.9999105 ]],\n",
       "\n",
       "        [[ 0.99970245],\n",
       "         [ 0.9997154 ],\n",
       "         [ 0.999252  ],\n",
       "         [ 0.99929917],\n",
       "         [ 0.9993683 ],\n",
       "         [ 0.9993429 ],\n",
       "         [ 0.9992643 ],\n",
       "         [ 0.99920607],\n",
       "         [ 0.9992116 ],\n",
       "         [ 0.9992703 ],\n",
       "         [ 0.9992791 ],\n",
       "         [ 0.9993155 ],\n",
       "         [ 0.99935   ],\n",
       "         [ 0.99934983],\n",
       "         [ 0.9993723 ],\n",
       "         [ 0.9994113 ],\n",
       "         [ 0.9994269 ],\n",
       "         [ 0.9994758 ],\n",
       "         [ 0.9995194 ],\n",
       "         [ 0.99955106],\n",
       "         [ 0.9995383 ],\n",
       "         [ 0.99954075],\n",
       "         [ 0.9995553 ],\n",
       "         [ 0.9996122 ],\n",
       "         [ 0.99954367],\n",
       "         [ 0.9996562 ],\n",
       "         [ 0.9999125 ],\n",
       "         [ 0.99996245]],\n",
       "\n",
       "        [[ 0.99973035],\n",
       "         [ 0.99974346],\n",
       "         [ 0.99908805],\n",
       "         [ 0.9991584 ],\n",
       "         [ 0.9992642 ],\n",
       "         [ 0.99922943],\n",
       "         [ 0.99912125],\n",
       "         [ 0.9990707 ],\n",
       "         [ 0.9991194 ],\n",
       "         [ 0.99919134],\n",
       "         [ 0.9992442 ],\n",
       "         [ 0.9993373 ],\n",
       "         [ 0.9993515 ],\n",
       "         [ 0.99922305],\n",
       "         [ 0.9991913 ],\n",
       "         [ 0.9992318 ],\n",
       "         [ 0.9991993 ],\n",
       "         [ 0.9991913 ],\n",
       "         [ 0.9991942 ],\n",
       "         [ 0.99920547],\n",
       "         [ 0.99915904],\n",
       "         [ 0.9991689 ],\n",
       "         [ 0.9992429 ],\n",
       "         [ 0.9994013 ],\n",
       "         [ 0.9993566 ],\n",
       "         [ 0.99951833],\n",
       "         [ 0.99991935],\n",
       "         [ 0.9999803 ]],\n",
       "\n",
       "        [[ 0.99971473],\n",
       "         [ 0.9996919 ],\n",
       "         [ 0.99910396],\n",
       "         [ 0.99913895],\n",
       "         [ 0.99909586],\n",
       "         [ 0.998763  ],\n",
       "         [ 0.9984763 ],\n",
       "         [ 0.9983365 ],\n",
       "         [ 0.99836886],\n",
       "         [ 0.9986736 ],\n",
       "         [ 0.9989437 ],\n",
       "         [ 0.99932486],\n",
       "         [ 0.99943364],\n",
       "         [ 0.99911326],\n",
       "         [ 0.998549  ],\n",
       "         [ 0.9983461 ],\n",
       "         [ 0.9987951 ],\n",
       "         [ 0.99914247],\n",
       "         [ 0.9992601 ],\n",
       "         [ 0.9993131 ],\n",
       "         [ 0.9993002 ],\n",
       "         [ 0.99932337],\n",
       "         [ 0.9993892 ],\n",
       "         [ 0.99951553],\n",
       "         [ 0.99945354],\n",
       "         [ 0.99953884],\n",
       "         [ 0.99992645],\n",
       "         [ 0.99998754]],\n",
       "\n",
       "        [[ 0.99964976],\n",
       "         [ 0.99965143],\n",
       "         [ 0.9991799 ],\n",
       "         [ 0.9992053 ],\n",
       "         [ 0.9987565 ],\n",
       "         [ 0.9962369 ],\n",
       "         [ 0.9807135 ],\n",
       "         [ 0.9595077 ],\n",
       "         [ 0.9408782 ],\n",
       "         [ 0.9068808 ],\n",
       "         [ 0.89352524],\n",
       "         [ 0.8774075 ],\n",
       "         [ 0.79598373],\n",
       "         [ 0.6725246 ],\n",
       "         [ 0.49044794],\n",
       "         [ 0.7030348 ],\n",
       "         [ 0.9692913 ],\n",
       "         [ 0.9972705 ],\n",
       "         [ 0.9990185 ],\n",
       "         [ 0.99924874],\n",
       "         [ 0.99928486],\n",
       "         [ 0.9993025 ],\n",
       "         [ 0.99935406],\n",
       "         [ 0.9994766 ],\n",
       "         [ 0.99937916],\n",
       "         [ 0.9994685 ],\n",
       "         [ 0.999931  ],\n",
       "         [ 0.9999911 ]],\n",
       "\n",
       "        [[ 0.9996358 ],\n",
       "         [ 0.99972165],\n",
       "         [ 0.99933195],\n",
       "         [ 0.99927235],\n",
       "         [ 0.9983992 ],\n",
       "         [ 0.9793554 ],\n",
       "         [ 0.35266387],\n",
       "         [-0.50450444],\n",
       "         [-0.5938313 ],\n",
       "         [-0.6214046 ],\n",
       "         [-0.63276005],\n",
       "         [-0.6719487 ],\n",
       "         [-0.7062752 ],\n",
       "         [-0.7670922 ],\n",
       "         [-0.7419491 ],\n",
       "         [-0.02374439],\n",
       "         [ 0.93425786],\n",
       "         [ 0.99687856],\n",
       "         [ 0.9991396 ],\n",
       "         [ 0.9993736 ],\n",
       "         [ 0.9994215 ],\n",
       "         [ 0.99942935],\n",
       "         [ 0.9994608 ],\n",
       "         [ 0.9995628 ],\n",
       "         [ 0.9994176 ],\n",
       "         [ 0.9994838 ],\n",
       "         [ 0.9999373 ],\n",
       "         [ 0.99999285]],\n",
       "\n",
       "        [[ 0.99963105],\n",
       "         [ 0.9997205 ],\n",
       "         [ 0.9991954 ],\n",
       "         [ 0.99912393],\n",
       "         [ 0.99841976],\n",
       "         [ 0.9845041 ],\n",
       "         [ 0.63660294],\n",
       "         [ 0.16673705],\n",
       "         [ 0.08816644],\n",
       "         [ 0.03107047],\n",
       "         [ 0.09162036],\n",
       "         [ 0.20254335],\n",
       "         [ 0.29902482],\n",
       "         [ 0.40344077],\n",
       "         [ 0.5271356 ],\n",
       "         [ 0.8189446 ],\n",
       "         [ 0.9834984 ],\n",
       "         [ 0.99785984],\n",
       "         [ 0.9990229 ],\n",
       "         [ 0.9992404 ],\n",
       "         [ 0.99929273],\n",
       "         [ 0.9993028 ],\n",
       "         [ 0.99933946],\n",
       "         [ 0.9994833 ],\n",
       "         [ 0.99931705],\n",
       "         [ 0.99943966],\n",
       "         [ 0.9999422 ],\n",
       "         [ 0.99999404]],\n",
       "\n",
       "        [[ 0.99963146],\n",
       "         [ 0.99978656],\n",
       "         [ 0.9993201 ],\n",
       "         [ 0.99923253],\n",
       "         [ 0.9992595 ],\n",
       "         [ 0.99875546],\n",
       "         [ 0.9937846 ],\n",
       "         [ 0.9886164 ],\n",
       "         [ 0.9920884 ],\n",
       "         [ 0.9942149 ],\n",
       "         [ 0.9953466 ],\n",
       "         [ 0.9963252 ],\n",
       "         [ 0.99755096],\n",
       "         [ 0.9984733 ],\n",
       "         [ 0.9989283 ],\n",
       "         [ 0.99897265],\n",
       "         [ 0.99910295],\n",
       "         [ 0.9991696 ],\n",
       "         [ 0.99916136],\n",
       "         [ 0.999234  ],\n",
       "         [ 0.99928   ],\n",
       "         [ 0.99930894],\n",
       "         [ 0.99937445],\n",
       "         [ 0.9995248 ],\n",
       "         [ 0.99935156],\n",
       "         [ 0.99946207],\n",
       "         [ 0.9999466 ],\n",
       "         [ 0.9999948 ]],\n",
       "\n",
       "        [[ 0.9995958 ],\n",
       "         [ 0.99976134],\n",
       "         [ 0.9992727 ],\n",
       "         [ 0.999156  ],\n",
       "         [ 0.99919796],\n",
       "         [ 0.9983399 ],\n",
       "         [ 0.9938806 ],\n",
       "         [ 0.99548787],\n",
       "         [ 0.9988797 ],\n",
       "         [ 0.99950874],\n",
       "         [ 0.9995344 ],\n",
       "         [ 0.9994735 ],\n",
       "         [ 0.9993417 ],\n",
       "         [ 0.9992742 ],\n",
       "         [ 0.9992462 ],\n",
       "         [ 0.99916583],\n",
       "         [ 0.99909294],\n",
       "         [ 0.999071  ],\n",
       "         [ 0.9990645 ],\n",
       "         [ 0.999141  ],\n",
       "         [ 0.9991489 ],\n",
       "         [ 0.9991818 ],\n",
       "         [ 0.99927825],\n",
       "         [ 0.99945235],\n",
       "         [ 0.99924684],\n",
       "         [ 0.9994017 ],\n",
       "         [ 0.9999512 ],\n",
       "         [ 0.99999565]],\n",
       "\n",
       "        [[ 0.9995597 ],\n",
       "         [ 0.99971896],\n",
       "         [ 0.99922144],\n",
       "         [ 0.99916863],\n",
       "         [ 0.9991308 ],\n",
       "         [ 0.99494606],\n",
       "         [ 0.95368147],\n",
       "         [ 0.9676563 ],\n",
       "         [ 0.99822813],\n",
       "         [ 0.9993228 ],\n",
       "         [ 0.9990366 ],\n",
       "         [ 0.9986492 ],\n",
       "         [ 0.99836934],\n",
       "         [ 0.9985299 ],\n",
       "         [ 0.9989078 ],\n",
       "         [ 0.9990721 ],\n",
       "         [ 0.99909276],\n",
       "         [ 0.99901366],\n",
       "         [ 0.9990036 ],\n",
       "         [ 0.9991263 ],\n",
       "         [ 0.9991311 ],\n",
       "         [ 0.99917996],\n",
       "         [ 0.99929464],\n",
       "         [ 0.9994623 ],\n",
       "         [ 0.99924004],\n",
       "         [ 0.9993881 ],\n",
       "         [ 0.99995524],\n",
       "         [ 0.99999636]],\n",
       "\n",
       "        [[ 0.9995554 ],\n",
       "         [ 0.99971366],\n",
       "         [ 0.99925774],\n",
       "         [ 0.9992404 ],\n",
       "         [ 0.9990621 ],\n",
       "         [ 0.98932767],\n",
       "         [ 0.74391675],\n",
       "         [ 0.8131818 ],\n",
       "         [ 0.9964709 ],\n",
       "         [ 0.99932826],\n",
       "         [ 0.99912995],\n",
       "         [ 0.9987971 ],\n",
       "         [ 0.9986253 ],\n",
       "         [ 0.9988782 ],\n",
       "         [ 0.99920875],\n",
       "         [ 0.9991945 ],\n",
       "         [ 0.9991116 ],\n",
       "         [ 0.99893594],\n",
       "         [ 0.9989738 ],\n",
       "         [ 0.9991432 ],\n",
       "         [ 0.99910194],\n",
       "         [ 0.99913996],\n",
       "         [ 0.999276  ],\n",
       "         [ 0.99945116],\n",
       "         [ 0.99919826],\n",
       "         [ 0.99938196],\n",
       "         [ 0.99995947],\n",
       "         [ 0.99999696]],\n",
       "\n",
       "        [[ 0.99956757],\n",
       "         [ 0.9997099 ],\n",
       "         [ 0.9992782 ],\n",
       "         [ 0.9992951 ],\n",
       "         [ 0.99920654],\n",
       "         [ 0.9925928 ],\n",
       "         [ 0.6233228 ],\n",
       "         [ 0.42227802],\n",
       "         [ 0.96772224],\n",
       "         [ 0.9987589 ],\n",
       "         [ 0.99924266],\n",
       "         [ 0.9992654 ],\n",
       "         [ 0.99913365],\n",
       "         [ 0.9992171 ],\n",
       "         [ 0.99925303],\n",
       "         [ 0.9988987 ],\n",
       "         [ 0.99876827],\n",
       "         [ 0.9987153 ],\n",
       "         [ 0.9990133 ],\n",
       "         [ 0.99919504],\n",
       "         [ 0.9991202 ],\n",
       "         [ 0.99915004],\n",
       "         [ 0.99927974],\n",
       "         [ 0.99945265],\n",
       "         [ 0.99918836],\n",
       "         [ 0.99943066],\n",
       "         [ 0.99996454],\n",
       "         [ 0.99999744]],\n",
       "\n",
       "        [[ 0.99957913],\n",
       "         [ 0.9997153 ],\n",
       "         [ 0.999276  ],\n",
       "         [ 0.9992787 ],\n",
       "         [ 0.99936783],\n",
       "         [ 0.9978896 ],\n",
       "         [ 0.74811226],\n",
       "         [-0.42599195],\n",
       "         [ 0.2018568 ],\n",
       "         [ 0.9686024 ],\n",
       "         [ 0.9986476 ],\n",
       "         [ 0.9992701 ],\n",
       "         [ 0.99930465],\n",
       "         [ 0.999227  ],\n",
       "         [ 0.99861413],\n",
       "         [ 0.9947404 ],\n",
       "         [ 0.9934197 ],\n",
       "         [ 0.9971074 ],\n",
       "         [ 0.99909854],\n",
       "         [ 0.9992869 ],\n",
       "         [ 0.99914867],\n",
       "         [ 0.99917763],\n",
       "         [ 0.999294  ],\n",
       "         [ 0.9994615 ],\n",
       "         [ 0.99920046],\n",
       "         [ 0.99946404],\n",
       "         [ 0.9999671 ],\n",
       "         [ 0.9999977 ]],\n",
       "\n",
       "        [[ 0.99960524],\n",
       "         [ 0.9997155 ],\n",
       "         [ 0.9992483 ],\n",
       "         [ 0.99920017],\n",
       "         [ 0.9993471 ],\n",
       "         [ 0.99928325],\n",
       "         [ 0.9835167 ],\n",
       "         [ 0.16709824],\n",
       "         [-0.74976474],\n",
       "         [-0.09392604],\n",
       "         [ 0.6504638 ],\n",
       "         [ 0.9016165 ],\n",
       "         [ 0.9410581 ],\n",
       "         [ 0.8997697 ],\n",
       "         [ 0.7526972 ],\n",
       "         [ 0.4395245 ],\n",
       "         [ 0.5195396 ],\n",
       "         [ 0.95578396],\n",
       "         [ 0.99791884],\n",
       "         [ 0.99919444],\n",
       "         [ 0.99918187],\n",
       "         [ 0.99916935],\n",
       "         [ 0.999251  ],\n",
       "         [ 0.9994216 ],\n",
       "         [ 0.99914354],\n",
       "         [ 0.99944896],\n",
       "         [ 0.9999679 ],\n",
       "         [ 0.99999785]],\n",
       "\n",
       "        [[ 0.9996294 ],\n",
       "         [ 0.99972594],\n",
       "         [ 0.9992266 ],\n",
       "         [ 0.99915916],\n",
       "         [ 0.999213  ],\n",
       "         [ 0.9994216 ],\n",
       "         [ 0.99891293],\n",
       "         [ 0.9476565 ],\n",
       "         [ 0.11573607],\n",
       "         [-0.7866297 ],\n",
       "         [-0.7299901 ],\n",
       "         [-0.5551819 ],\n",
       "         [-0.5093948 ],\n",
       "         [-0.59175205],\n",
       "         [-0.7129443 ],\n",
       "         [-0.8356149 ],\n",
       "         [-0.27758121],\n",
       "         [ 0.90566534],\n",
       "         [ 0.9966153 ],\n",
       "         [ 0.9990757 ],\n",
       "         [ 0.9991482 ],\n",
       "         [ 0.9991541 ],\n",
       "         [ 0.9992454 ],\n",
       "         [ 0.99942756],\n",
       "         [ 0.9991584 ],\n",
       "         [ 0.999455  ],\n",
       "         [ 0.999968  ],\n",
       "         [ 0.99999785]],\n",
       "\n",
       "        [[ 0.9996543 ],\n",
       "         [ 0.9997367 ],\n",
       "         [ 0.9992195 ],\n",
       "         [ 0.99912596],\n",
       "         [ 0.9991142 ],\n",
       "         [ 0.99918306],\n",
       "         [ 0.99937415],\n",
       "         [ 0.9985467 ],\n",
       "         [ 0.9713622 ],\n",
       "         [ 0.672674  ],\n",
       "         [ 0.37347293],\n",
       "         [ 0.13479075],\n",
       "         [ 0.11617879],\n",
       "         [ 0.22431   ],\n",
       "         [ 0.3748563 ],\n",
       "         [ 0.5332727 ],\n",
       "         [ 0.81579655],\n",
       "         [ 0.9874528 ],\n",
       "         [ 0.99856335],\n",
       "         [ 0.9991954 ],\n",
       "         [ 0.99911165],\n",
       "         [ 0.9990857 ],\n",
       "         [ 0.99917203],\n",
       "         [ 0.9993664 ],\n",
       "         [ 0.9990845 ],\n",
       "         [ 0.9994283 ],\n",
       "         [ 0.9999676 ],\n",
       "         [ 0.99999774]],\n",
       "\n",
       "        [[ 0.9996473 ],\n",
       "         [ 0.9997083 ],\n",
       "         [ 0.9991661 ],\n",
       "         [ 0.9990886 ],\n",
       "         [ 0.99907535],\n",
       "         [ 0.99908906],\n",
       "         [ 0.9991163 ],\n",
       "         [ 0.99933434],\n",
       "         [ 0.99934494],\n",
       "         [ 0.99864966],\n",
       "         [ 0.9969672 ],\n",
       "         [ 0.9951123 ],\n",
       "         [ 0.9943316 ],\n",
       "         [ 0.99433106],\n",
       "         [ 0.9944974 ],\n",
       "         [ 0.9962972 ],\n",
       "         [ 0.9980343 ],\n",
       "         [ 0.99902695],\n",
       "         [ 0.9992315 ],\n",
       "         [ 0.99917346],\n",
       "         [ 0.9990795 ],\n",
       "         [ 0.99909174],\n",
       "         [ 0.99915916],\n",
       "         [ 0.9993514 ],\n",
       "         [ 0.99904996],\n",
       "         [ 0.9994204 ],\n",
       "         [ 0.9999686 ],\n",
       "         [ 0.9999979 ]],\n",
       "\n",
       "        [[ 0.99966544],\n",
       "         [ 0.9997177 ],\n",
       "         [ 0.99924684],\n",
       "         [ 0.9991411 ],\n",
       "         [ 0.99912125],\n",
       "         [ 0.9991502 ],\n",
       "         [ 0.9990873 ],\n",
       "         [ 0.9991429 ],\n",
       "         [ 0.9993003 ],\n",
       "         [ 0.99943227],\n",
       "         [ 0.9995259 ],\n",
       "         [ 0.9994878 ],\n",
       "         [ 0.99941665],\n",
       "         [ 0.99934953],\n",
       "         [ 0.99935275],\n",
       "         [ 0.99936885],\n",
       "         [ 0.9993551 ],\n",
       "         [ 0.99929476],\n",
       "         [ 0.99921495],\n",
       "         [ 0.9992489 ],\n",
       "         [ 0.99921525],\n",
       "         [ 0.9991984 ],\n",
       "         [ 0.9992203 ],\n",
       "         [ 0.9993826 ],\n",
       "         [ 0.9990864 ],\n",
       "         [ 0.99943435],\n",
       "         [ 0.99996895],\n",
       "         [ 0.99999803]],\n",
       "\n",
       "        [[ 0.9996326 ],\n",
       "         [ 0.9996472 ],\n",
       "         [ 0.99912155],\n",
       "         [ 0.9989907 ],\n",
       "         [ 0.9989267 ],\n",
       "         [ 0.99894357],\n",
       "         [ 0.9988826 ],\n",
       "         [ 0.9988687 ],\n",
       "         [ 0.99889636],\n",
       "         [ 0.99897593],\n",
       "         [ 0.99906194],\n",
       "         [ 0.99904007],\n",
       "         [ 0.99889666],\n",
       "         [ 0.9987566 ],\n",
       "         [ 0.9988048 ],\n",
       "         [ 0.9989279 ],\n",
       "         [ 0.99900174],\n",
       "         [ 0.99905694],\n",
       "         [ 0.99910015],\n",
       "         [ 0.99919045],\n",
       "         [ 0.9991437 ],\n",
       "         [ 0.99905425],\n",
       "         [ 0.9990503 ],\n",
       "         [ 0.9992657 ],\n",
       "         [ 0.9989133 ],\n",
       "         [ 0.9993347 ],\n",
       "         [ 0.9999666 ],\n",
       "         [ 0.99999785]],\n",
       "\n",
       "        [[ 0.9996962 ],\n",
       "         [ 0.9997451 ],\n",
       "         [ 0.99939144],\n",
       "         [ 0.9992454 ],\n",
       "         [ 0.9991857 ],\n",
       "         [ 0.99915594],\n",
       "         [ 0.99906635],\n",
       "         [ 0.9990687 ],\n",
       "         [ 0.99908173],\n",
       "         [ 0.99913365],\n",
       "         [ 0.99917454],\n",
       "         [ 0.9991355 ],\n",
       "         [ 0.99898475],\n",
       "         [ 0.9988196 ],\n",
       "         [ 0.9988684 ],\n",
       "         [ 0.9990056 ],\n",
       "         [ 0.9990839 ],\n",
       "         [ 0.9991844 ],\n",
       "         [ 0.9992416 ],\n",
       "         [ 0.99930024],\n",
       "         [ 0.999238  ],\n",
       "         [ 0.99917114],\n",
       "         [ 0.99920446],\n",
       "         [ 0.99939775],\n",
       "         [ 0.99904716],\n",
       "         [ 0.9993869 ],\n",
       "         [ 0.99996394],\n",
       "         [ 0.99999756]],\n",
       "\n",
       "        [[ 0.99962723],\n",
       "         [ 0.9995741 ],\n",
       "         [ 0.9989958 ],\n",
       "         [ 0.9989982 ],\n",
       "         [ 0.9989575 ],\n",
       "         [ 0.9989407 ],\n",
       "         [ 0.99881554],\n",
       "         [ 0.9988211 ],\n",
       "         [ 0.99883544],\n",
       "         [ 0.9989094 ],\n",
       "         [ 0.99894595],\n",
       "         [ 0.99890965],\n",
       "         [ 0.9987496 ],\n",
       "         [ 0.9985937 ],\n",
       "         [ 0.9986373 ],\n",
       "         [ 0.9988074 ],\n",
       "         [ 0.9989059 ],\n",
       "         [ 0.99897933],\n",
       "         [ 0.9989811 ],\n",
       "         [ 0.9990066 ],\n",
       "         [ 0.9988853 ],\n",
       "         [ 0.9988165 ],\n",
       "         [ 0.998884  ],\n",
       "         [ 0.9991698 ],\n",
       "         [ 0.9987501 ],\n",
       "         [ 0.9992368 ],\n",
       "         [ 0.9999484 ],\n",
       "         [ 0.99999696]],\n",
       "\n",
       "        [[ 0.9996742 ],\n",
       "         [ 0.99976057],\n",
       "         [ 0.99958545],\n",
       "         [ 0.99960303],\n",
       "         [ 0.9995894 ],\n",
       "         [ 0.9996034 ],\n",
       "         [ 0.9995561 ],\n",
       "         [ 0.99954504],\n",
       "         [ 0.99953383],\n",
       "         [ 0.9995573 ],\n",
       "         [ 0.9995698 ],\n",
       "         [ 0.9995715 ],\n",
       "         [ 0.9995282 ],\n",
       "         [ 0.9994857 ],\n",
       "         [ 0.9994942 ],\n",
       "         [ 0.9995513 ],\n",
       "         [ 0.9995702 ],\n",
       "         [ 0.99956065],\n",
       "         [ 0.99952894],\n",
       "         [ 0.9995263 ],\n",
       "         [ 0.9995102 ],\n",
       "         [ 0.99953824],\n",
       "         [ 0.99960244],\n",
       "         [ 0.9996871 ],\n",
       "         [ 0.99944675],\n",
       "         [ 0.9995815 ],\n",
       "         [ 0.9999213 ],\n",
       "         [ 0.99999297]],\n",
       "\n",
       "        [[ 0.9985324 ],\n",
       "         [ 0.99753606],\n",
       "         [ 0.9982845 ],\n",
       "         [ 0.99842745],\n",
       "         [ 0.99869907],\n",
       "         [ 0.99889016],\n",
       "         [ 0.9988844 ],\n",
       "         [ 0.9989072 ],\n",
       "         [ 0.99887353],\n",
       "         [ 0.998904  ],\n",
       "         [ 0.99889016],\n",
       "         [ 0.9988943 ],\n",
       "         [ 0.9988194 ],\n",
       "         [ 0.9987711 ],\n",
       "         [ 0.99880826],\n",
       "         [ 0.9989042 ],\n",
       "         [ 0.9989289 ],\n",
       "         [ 0.99889505],\n",
       "         [ 0.99884194],\n",
       "         [ 0.9988635 ],\n",
       "         [ 0.99885076],\n",
       "         [ 0.99894774],\n",
       "         [ 0.9991776 ],\n",
       "         [ 0.9993895 ],\n",
       "         [ 0.9992099 ],\n",
       "         [ 0.99931765],\n",
       "         [ 0.9997549 ],\n",
       "         [ 0.9999857 ]],\n",
       "\n",
       "        [[ 0.99969137],\n",
       "         [ 0.99989563],\n",
       "         [ 0.9997693 ],\n",
       "         [ 0.99972355],\n",
       "         [ 0.99980485],\n",
       "         [ 0.9998134 ],\n",
       "         [ 0.9997869 ],\n",
       "         [ 0.9997726 ],\n",
       "         [ 0.9997484 ],\n",
       "         [ 0.9997326 ],\n",
       "         [ 0.9997158 ],\n",
       "         [ 0.9997065 ],\n",
       "         [ 0.9997012 ],\n",
       "         [ 0.99969894],\n",
       "         [ 0.9996937 ],\n",
       "         [ 0.9996882 ],\n",
       "         [ 0.9996784 ],\n",
       "         [ 0.9996784 ],\n",
       "         [ 0.9996977 ],\n",
       "         [ 0.9997364 ],\n",
       "         [ 0.999777  ],\n",
       "         [ 0.99981105],\n",
       "         [ 0.9998581 ],\n",
       "         [ 0.99988   ],\n",
       "         [ 0.999825  ],\n",
       "         [ 0.99990076],\n",
       "         [ 0.99996614],\n",
       "         [ 0.99998915]],\n",
       "\n",
       "        [[ 0.9996327 ],\n",
       "         [ 0.99995667],\n",
       "         [ 0.9999683 ],\n",
       "         [ 0.99997425],\n",
       "         [ 0.9999842 ],\n",
       "         [ 0.99998516],\n",
       "         [ 0.99998504],\n",
       "         [ 0.9999839 ],\n",
       "         [ 0.99998224],\n",
       "         [ 0.9999796 ],\n",
       "         [ 0.9999765 ],\n",
       "         [ 0.9999737 ],\n",
       "         [ 0.9999709 ],\n",
       "         [ 0.9999702 ],\n",
       "         [ 0.9999674 ],\n",
       "         [ 0.99996465],\n",
       "         [ 0.99996406],\n",
       "         [ 0.9999667 ],\n",
       "         [ 0.9999732 ],\n",
       "         [ 0.9999792 ],\n",
       "         [ 0.99998474],\n",
       "         [ 0.99998784],\n",
       "         [ 0.9999892 ],\n",
       "         [ 0.9999872 ],\n",
       "         [ 0.9999369 ],\n",
       "         [ 0.9998593 ],\n",
       "         [ 0.99913436],\n",
       "         [ 0.9998454 ]],\n",
       "\n",
       "        [[ 0.9999488 ],\n",
       "         [ 0.9999835 ],\n",
       "         [ 0.99999464],\n",
       "         [ 0.99999803],\n",
       "         [ 0.9999992 ],\n",
       "         [ 0.9999995 ],\n",
       "         [ 0.9999994 ],\n",
       "         [ 0.99999946],\n",
       "         [ 0.9999993 ],\n",
       "         [ 0.99999905],\n",
       "         [ 0.9999988 ],\n",
       "         [ 0.9999985 ],\n",
       "         [ 0.9999981 ],\n",
       "         [ 0.99999815],\n",
       "         [ 0.999998  ],\n",
       "         [ 0.99999774],\n",
       "         [ 0.9999974 ],\n",
       "         [ 0.9999976 ],\n",
       "         [ 0.99999803],\n",
       "         [ 0.9999984 ],\n",
       "         [ 0.9999989 ],\n",
       "         [ 0.9999992 ],\n",
       "         [ 0.9999994 ],\n",
       "         [ 0.99999946],\n",
       "         [ 0.9999968 ],\n",
       "         [ 0.9999629 ],\n",
       "         [ 0.9999743 ],\n",
       "         [ 0.99995536]]]], dtype=float32)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01885445, -0.09043905, -0.08474787, -0.09249571, -0.09400196,\n",
       "       -0.09758668, -0.10315984, -0.11083569, -0.11560372, -0.11533213,\n",
       "       -0.11428133, -0.10922816, -0.10963915, -0.11126538, -0.11048752,\n",
       "       -0.10694195, -0.1028188 , -0.10580929, -0.10809049, -0.10763772,\n",
       "       -0.10965155, -0.10563087, -0.10557331, -0.09269907, -0.09170057,\n",
       "       -0.03120106, -0.01600707,  0.0479105 ], dtype=float32)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results[6][7][0, 0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05900833, -0.09002143, -0.12935424, -0.1266709 , -0.1152868 ,\n",
       "       -0.11829704, -0.12016031, -0.10493308, -0.09944692, -0.08946908,\n",
       "       -0.08380413, -0.09614819, -0.09537685, -0.09238225, -0.07581463,\n",
       "       -0.06762719, -0.06412295, -0.06768554, -0.07433248, -0.07418811,\n",
       "       -0.07031867, -0.06839621, -0.06274238, -0.07325906, -0.06952679,\n",
       "       -0.0997048 , -0.06428728,  0.07308565], dtype=float32)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results[4][-1][0, 0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5379593 , -0.33272868],\n",
       "       [ 0.28598887, -0.30941498]], dtype=float32)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results[3][13][0, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_image_arr(arr):\n",
    "    arr = np.uint8(arr * 256)\n",
    "    arr = arr.reshape(arr.shape[:-1])\n",
    "    display(Image.fromarray(arr, mode='L').resize((224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beta1_power', []),\n",
       " ('beta1_power_1', []),\n",
       " ('beta2_power', []),\n",
       " ('beta2_power_1', []),\n",
       " ('discriminator/conv_layers/g_conv0/LayerNorm/beta', [64]),\n",
       " ('discriminator/conv_layers/g_conv0/LayerNorm/beta/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv0/LayerNorm/beta/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv0/LayerNorm/gamma', [64]),\n",
       " ('discriminator/conv_layers/g_conv0/LayerNorm/gamma/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv0/LayerNorm/gamma/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv0/conv2d/bias', [64]),\n",
       " ('discriminator/conv_layers/g_conv0/conv2d/bias/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv0/conv2d/bias/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv0/conv2d/kernel', [3, 3, 2, 64]),\n",
       " ('discriminator/conv_layers/g_conv0/conv2d/kernel/Adam', [3, 3, 2, 64]),\n",
       " ('discriminator/conv_layers/g_conv0/conv2d/kernel/Adam_1', [3, 3, 2, 64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm/beta', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm/beta/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm/beta/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm/gamma', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm/gamma/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm/gamma/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_1/beta', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_1/beta/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_1/beta/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_1/gamma', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_1/gamma/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_1/gamma/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_2/beta', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_2/beta/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_2/beta/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_2/gamma', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_2/gamma/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_2/gamma/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_3/beta', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_3/beta/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_3/beta/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_3/gamma', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_3/gamma/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_3/gamma/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_4/beta', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_4/beta/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_4/beta/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_4/gamma', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_4/gamma/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_4/gamma/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_5/beta', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_5/beta/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_5/beta/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_5/gamma', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_5/gamma/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/LayerNorm_5/gamma/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d/bias', [2]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d/bias/Adam', [2]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d/bias/Adam_1', [2]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d/kernel', [3, 3, 2, 2]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d/kernel/Adam', [3, 3, 2, 2]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d/kernel/Adam_1', [3, 3, 2, 2]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_1/bias', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_1/bias/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_1/bias/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_1/kernel', [3, 3, 66, 64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_1/kernel/Adam', [3, 3, 66, 64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_1/kernel/Adam_1', [3, 3, 66, 64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_2/bias', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_2/bias/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_2/bias/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_2/kernel', [3, 3, 128, 64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_2/kernel/Adam', [3, 3, 128, 64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_2/kernel/Adam_1', [3, 3, 128, 64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_3/bias', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_3/bias/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_3/bias/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_3/kernel', [3, 3, 192, 64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_3/kernel/Adam', [3, 3, 192, 64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_3/kernel/Adam_1', [3, 3, 192, 64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_4/bias', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_4/bias/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_4/bias/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_4/kernel', [3, 3, 256, 64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_4/kernel/Adam', [3, 3, 256, 64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_4/kernel/Adam_1', [3, 3, 256, 64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_5/bias', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_5/bias/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_5/bias/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_5/kernel', [3, 3, 320, 64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_5/kernel/Adam', [3, 3, 320, 64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_5/kernel/Adam_1', [3, 3, 320, 64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_6/bias', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_6/bias/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_6/bias/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_6/kernel', [3, 3, 384, 64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_6/kernel/Adam', [3, 3, 384, 64]),\n",
       " ('discriminator/conv_layers/g_conv1/conv2d_6/kernel/Adam_1', [3, 3, 384, 64]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm/beta', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm/beta/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm/beta/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm/gamma', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm/gamma/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm/gamma/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_1/beta', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_1/beta/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_1/beta/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_1/gamma', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_1/gamma/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_1/gamma/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_2/beta', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_2/beta/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_2/beta/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_2/gamma', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_2/gamma/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_2/gamma/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_3/beta', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_3/beta/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_3/beta/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_3/gamma', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_3/gamma/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_3/gamma/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_4/beta', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_4/beta/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_4/beta/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_4/gamma', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_4/gamma/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_4/gamma/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_5/beta', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_5/beta/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_5/beta/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_5/gamma', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_5/gamma/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/LayerNorm_5/gamma/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d/bias', [64]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d/bias/Adam', [64]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d/bias/Adam_1', [64]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d/kernel', [3, 3, 64, 64]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d/kernel/Adam', [3, 3, 64, 64]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d/kernel/Adam_1', [3, 3, 64, 64]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_1/bias', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_1/bias/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_1/bias/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_1/kernel', [3, 3, 128, 128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_1/kernel/Adam', [3, 3, 128, 128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_1/kernel/Adam_1',\n",
       "  [3, 3, 128, 128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_2/bias', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_2/bias/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_2/bias/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_2/kernel', [3, 3, 192, 128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_2/kernel/Adam', [3, 3, 192, 128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_2/kernel/Adam_1',\n",
       "  [3, 3, 192, 128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_3/bias', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_3/bias/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_3/bias/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_3/kernel', [3, 3, 320, 128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_3/kernel/Adam', [3, 3, 320, 128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_3/kernel/Adam_1',\n",
       "  [3, 3, 320, 128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_4/bias', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_4/bias/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_4/bias/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_4/kernel', [3, 3, 448, 128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_4/kernel/Adam', [3, 3, 448, 128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_4/kernel/Adam_1',\n",
       "  [3, 3, 448, 128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_5/bias', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_5/bias/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_5/bias/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_5/kernel', [3, 3, 576, 128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_5/kernel/Adam', [3, 3, 576, 128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_5/kernel/Adam_1',\n",
       "  [3, 3, 576, 128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_6/bias', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_6/bias/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_6/bias/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_6/kernel', [3, 3, 704, 128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_6/kernel/Adam', [3, 3, 704, 128]),\n",
       " ('discriminator/conv_layers/g_conv2/conv2d_6/kernel/Adam_1',\n",
       "  [3, 3, 704, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm/beta', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm/beta/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm/beta/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm/gamma', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm/gamma/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm/gamma/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_1/beta', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_1/beta/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_1/beta/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_1/gamma', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_1/gamma/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_1/gamma/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_2/beta', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_2/beta/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_2/beta/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_2/gamma', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_2/gamma/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_2/gamma/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_3/beta', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_3/beta/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_3/beta/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_3/gamma', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_3/gamma/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_3/gamma/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_4/beta', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_4/beta/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_4/beta/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_4/gamma', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_4/gamma/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_4/gamma/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_5/beta', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_5/beta/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_5/beta/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_5/gamma', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_5/gamma/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/LayerNorm_5/gamma/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d/bias', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d/bias/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d/bias/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d/kernel', [3, 3, 128, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d/kernel/Adam', [3, 3, 128, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d/kernel/Adam_1', [3, 3, 128, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_1/bias', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_1/bias/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_1/bias/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_1/kernel', [3, 3, 256, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_1/kernel/Adam', [3, 3, 256, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_1/kernel/Adam_1',\n",
       "  [3, 3, 256, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_2/bias', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_2/bias/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_2/bias/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_2/kernel', [3, 3, 256, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_2/kernel/Adam', [3, 3, 256, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_2/kernel/Adam_1',\n",
       "  [3, 3, 256, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_3/bias', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_3/bias/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_3/bias/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_3/kernel', [3, 3, 384, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_3/kernel/Adam', [3, 3, 384, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_3/kernel/Adam_1',\n",
       "  [3, 3, 384, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_4/bias', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_4/bias/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_4/bias/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_4/kernel', [3, 3, 512, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_4/kernel/Adam', [3, 3, 512, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_4/kernel/Adam_1',\n",
       "  [3, 3, 512, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_5/bias', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_5/bias/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_5/bias/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_5/kernel', [3, 3, 640, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_5/kernel/Adam', [3, 3, 640, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_5/kernel/Adam_1',\n",
       "  [3, 3, 640, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_6/bias', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_6/bias/Adam', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_6/bias/Adam_1', [128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_6/kernel', [3, 3, 768, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_6/kernel/Adam', [3, 3, 768, 128]),\n",
       " ('discriminator/conv_layers/g_conv3/conv2d_6/kernel/Adam_1',\n",
       "  [3, 3, 768, 128]),\n",
       " ('discriminator/discriminator_dense_block/dense/bias', [1024]),\n",
       " ('discriminator/discriminator_dense_block/dense/bias/Adam', [1024]),\n",
       " ('discriminator/discriminator_dense_block/dense/bias/Adam_1', [1024]),\n",
       " ('discriminator/discriminator_dense_block/dense/kernel', [128, 1024]),\n",
       " ('discriminator/discriminator_dense_block/dense/kernel/Adam', [128, 1024]),\n",
       " ('discriminator/discriminator_dense_block/dense/kernel/Adam_1', [128, 1024]),\n",
       " ('discriminator/discriminator_out_block/outputs/bias', [1]),\n",
       " ('discriminator/discriminator_out_block/outputs/bias/Adam', [1]),\n",
       " ('discriminator/discriminator_out_block/outputs/bias/Adam_1', [1]),\n",
       " ('discriminator/discriminator_out_block/outputs/kernel', [1536, 1]),\n",
       " ('discriminator/discriminator_out_block/outputs/kernel/Adam', [1536, 1]),\n",
       " ('discriminator/discriminator_out_block/outputs/kernel/Adam_1', [1536, 1]),\n",
       " ('generator/conv_layers/g_conv0/BatchNorm/beta', [64]),\n",
       " ('generator/conv_layers/g_conv0/BatchNorm/beta/Adam', [64]),\n",
       " ('generator/conv_layers/g_conv0/BatchNorm/beta/Adam_1', [64]),\n",
       " ('generator/conv_layers/g_conv0/BatchNorm/gamma', [64]),\n",
       " ('generator/conv_layers/g_conv0/BatchNorm/gamma/Adam', [64]),\n",
       " ('generator/conv_layers/g_conv0/BatchNorm/gamma/Adam_1', [64]),\n",
       " ('generator/conv_layers/g_conv0/BatchNorm/moving_mean', [64]),\n",
       " ('generator/conv_layers/g_conv0/BatchNorm/moving_stddev', [64]),\n",
       " ('generator/conv_layers/g_conv0/BatchNorm/moving_variance', [64]),\n",
       " ('generator/conv_layers/g_conv0/BatchNorm/renorm_mean', [64]),\n",
       " ('generator/conv_layers/g_conv0/BatchNorm/renorm_stddev', [64]),\n",
       " ('generator/conv_layers/g_conv0/conv2d/bias', [64]),\n",
       " ('generator/conv_layers/g_conv0/conv2d/bias/Adam', [64]),\n",
       " ('generator/conv_layers/g_conv0/conv2d/bias/Adam_1', [64]),\n",
       " ('generator/conv_layers/g_conv0/conv2d/kernel', [3, 3, 1, 64]),\n",
       " ('generator/conv_layers/g_conv0/conv2d/kernel/Adam', [3, 3, 1, 64]),\n",
       " ('generator/conv_layers/g_conv0/conv2d/kernel/Adam_1', [3, 3, 1, 64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm/beta', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm/beta/Adam', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm/beta/Adam_1', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm/gamma', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm/gamma/Adam', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm/gamma/Adam_1', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm/moving_mean', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm/moving_stddev', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm/moving_variance', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm/renorm_mean', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm/renorm_stddev', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_1/beta', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_1/beta/Adam', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_1/beta/Adam_1', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_1/gamma', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_1/gamma/Adam', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_1/gamma/Adam_1', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_1/moving_mean', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_1/moving_stddev', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_1/moving_variance', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_1/renorm_mean', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_1/renorm_stddev', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_2/beta', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_2/beta/Adam', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_2/beta/Adam_1', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_2/gamma', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_2/gamma/Adam', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_2/gamma/Adam_1', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_2/moving_mean', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_2/moving_stddev', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_2/moving_variance', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_2/renorm_mean', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_2/renorm_stddev', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_3/beta', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_3/beta/Adam', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_3/beta/Adam_1', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_3/gamma', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_3/gamma/Adam', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_3/gamma/Adam_1', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_3/moving_mean', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_3/moving_stddev', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_3/moving_variance', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_3/renorm_mean', [64]),\n",
       " ('generator/conv_layers/g_conv1/BatchNorm_3/renorm_stddev', [64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d/bias', [1]),\n",
       " ('generator/conv_layers/g_conv1/conv2d/bias/Adam', [1]),\n",
       " ('generator/conv_layers/g_conv1/conv2d/bias/Adam_1', [1]),\n",
       " ('generator/conv_layers/g_conv1/conv2d/kernel', [3, 3, 1, 1]),\n",
       " ('generator/conv_layers/g_conv1/conv2d/kernel/Adam', [3, 3, 1, 1]),\n",
       " ('generator/conv_layers/g_conv1/conv2d/kernel/Adam_1', [3, 3, 1, 1]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_1/bias', [64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_1/bias/Adam', [64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_1/bias/Adam_1', [64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_1/kernel', [3, 3, 65, 64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_1/kernel/Adam', [3, 3, 65, 64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_1/kernel/Adam_1', [3, 3, 65, 64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_2/bias', [64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_2/bias/Adam', [64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_2/bias/Adam_1', [64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_2/kernel', [3, 3, 128, 64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_2/kernel/Adam', [3, 3, 128, 64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_2/kernel/Adam_1', [3, 3, 128, 64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_3/bias', [64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_3/bias/Adam', [64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_3/bias/Adam_1', [64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_3/kernel', [3, 3, 192, 64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_3/kernel/Adam', [3, 3, 192, 64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_3/kernel/Adam_1', [3, 3, 192, 64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_4/bias', [64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_4/bias/Adam', [64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_4/bias/Adam_1', [64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_4/kernel', [3, 3, 256, 64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_4/kernel/Adam', [3, 3, 256, 64]),\n",
       " ('generator/conv_layers/g_conv1/conv2d_4/kernel/Adam_1', [3, 3, 256, 64]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm/beta', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm/beta/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm/beta/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm/gamma', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm/gamma/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm/gamma/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm/moving_mean', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm/moving_stddev', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm/moving_variance', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm/renorm_mean', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm/renorm_stddev', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_1/beta', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_1/beta/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_1/beta/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_1/gamma', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_1/gamma/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_1/gamma/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_1/moving_mean', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_1/moving_stddev', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_1/moving_variance', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_1/renorm_mean', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_1/renorm_stddev', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_2/beta', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_2/beta/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_2/beta/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_2/gamma', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_2/gamma/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_2/gamma/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_2/moving_mean', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_2/moving_stddev', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_2/moving_variance', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_2/renorm_mean', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_2/renorm_stddev', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_3/beta', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_3/beta/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_3/beta/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_3/gamma', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_3/gamma/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_3/gamma/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_3/moving_mean', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_3/moving_stddev', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_3/moving_variance', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_3/renorm_mean', [128]),\n",
       " ('generator/conv_layers/g_conv2/BatchNorm_3/renorm_stddev', [128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d/bias', [64]),\n",
       " ('generator/conv_layers/g_conv2/conv2d/bias/Adam', [64]),\n",
       " ('generator/conv_layers/g_conv2/conv2d/bias/Adam_1', [64]),\n",
       " ('generator/conv_layers/g_conv2/conv2d/kernel', [3, 3, 64, 64]),\n",
       " ('generator/conv_layers/g_conv2/conv2d/kernel/Adam', [3, 3, 64, 64]),\n",
       " ('generator/conv_layers/g_conv2/conv2d/kernel/Adam_1', [3, 3, 64, 64]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_1/bias', [128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_1/bias/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_1/bias/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_1/kernel', [3, 3, 128, 128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_1/kernel/Adam', [3, 3, 128, 128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_1/kernel/Adam_1', [3, 3, 128, 128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_2/bias', [128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_2/bias/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_2/bias/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_2/kernel', [3, 3, 192, 128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_2/kernel/Adam', [3, 3, 192, 128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_2/kernel/Adam_1', [3, 3, 192, 128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_3/bias', [128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_3/bias/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_3/bias/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_3/kernel', [3, 3, 320, 128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_3/kernel/Adam', [3, 3, 320, 128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_3/kernel/Adam_1', [3, 3, 320, 128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_4/bias', [128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_4/bias/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_4/bias/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_4/kernel', [3, 3, 448, 128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_4/kernel/Adam', [3, 3, 448, 128]),\n",
       " ('generator/conv_layers/g_conv2/conv2d_4/kernel/Adam_1', [3, 3, 448, 128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm/beta', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm/beta/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm/beta/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm/gamma', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm/gamma/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm/gamma/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm/moving_mean', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm/moving_stddev', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm/moving_variance', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm/renorm_mean', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm/renorm_stddev', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_1/beta', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_1/beta/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_1/beta/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_1/gamma', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_1/gamma/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_1/gamma/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_1/moving_mean', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_1/moving_stddev', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_1/moving_variance', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_1/renorm_mean', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_1/renorm_stddev', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_2/beta', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_2/beta/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_2/beta/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_2/gamma', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_2/gamma/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_2/gamma/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_2/moving_mean', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_2/moving_stddev', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_2/moving_variance', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_2/renorm_mean', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_2/renorm_stddev', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_3/beta', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_3/beta/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_3/beta/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_3/gamma', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_3/gamma/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_3/gamma/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_3/moving_mean', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_3/moving_stddev', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_3/moving_variance', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_3/renorm_mean', [128]),\n",
       " ('generator/conv_layers/g_conv3/BatchNorm_3/renorm_stddev', [128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d/bias', [128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d/bias/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d/bias/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d/kernel', [3, 3, 128, 128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d/kernel/Adam', [3, 3, 128, 128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d/kernel/Adam_1', [3, 3, 128, 128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_1/bias', [128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_1/bias/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_1/bias/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_1/kernel', [3, 3, 256, 128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_1/kernel/Adam', [3, 3, 256, 128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_1/kernel/Adam_1', [3, 3, 256, 128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_2/bias', [128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_2/bias/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_2/bias/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_2/kernel', [3, 3, 256, 128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_2/kernel/Adam', [3, 3, 256, 128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_2/kernel/Adam_1', [3, 3, 256, 128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_3/bias', [128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_3/bias/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_3/bias/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_3/kernel', [3, 3, 384, 128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_3/kernel/Adam', [3, 3, 384, 128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_3/kernel/Adam_1', [3, 3, 384, 128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_4/bias', [128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_4/bias/Adam', [128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_4/bias/Adam_1', [128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_4/kernel', [3, 3, 512, 128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_4/kernel/Adam', [3, 3, 512, 128]),\n",
       " ('generator/conv_layers/g_conv3/conv2d_4/kernel/Adam_1', [3, 3, 512, 128]),\n",
       " ('generator/g_deconv_layers/BatchNorm/beta', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm/beta/Adam', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm/beta/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm/gamma', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm/gamma/Adam', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm/gamma/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm/moving_mean', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm/moving_stddev', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm/moving_variance', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm/renorm_mean', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm/renorm_stddev', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm_1/beta', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm_1/beta/Adam', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm_1/beta/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm_1/gamma', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm_1/gamma/Adam', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm_1/gamma/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm_1/moving_mean', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm_1/moving_stddev', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm_1/moving_variance', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm_1/renorm_mean', [64]),\n",
       " ('generator/g_deconv_layers/BatchNorm_1/renorm_stddev', [64]),\n",
       " ('generator/g_deconv_layers/conv2d/bias', [64]),\n",
       " ('generator/g_deconv_layers/conv2d/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/conv2d/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/conv2d/kernel', [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/conv2d/kernel/Adam', [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/conv2d/kernel/Adam_1', [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/conv2d_1/bias', [64]),\n",
       " ('generator/g_deconv_layers/conv2d_1/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/conv2d_1/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/conv2d_1/kernel', [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/conv2d_1/kernel/Adam', [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/conv2d_1/kernel/Adam_1', [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/conv2d_2/bias', [1]),\n",
       " ('generator/g_deconv_layers/conv2d_2/bias/Adam', [1]),\n",
       " ('generator/g_deconv_layers/conv2d_2/bias/Adam_1', [1]),\n",
       " ('generator/g_deconv_layers/conv2d_2/kernel', [3, 3, 64, 1]),\n",
       " ('generator/g_deconv_layers/conv2d_2/kernel/Adam', [3, 3, 64, 1]),\n",
       " ('generator/g_deconv_layers/conv2d_2/kernel/Adam_1', [3, 3, 64, 1]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm/beta', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm/beta/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm/beta/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm/gamma', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm/gamma/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm/gamma/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm/moving_mean', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm/moving_stddev', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm/moving_variance', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm/renorm_mean', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm/renorm_stddev', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_1/beta', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_1/beta/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_1/beta/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_1/gamma', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_1/gamma/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_1/gamma/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_1/moving_mean', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_1/moving_stddev', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_1/moving_variance', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_1/renorm_mean', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_1/renorm_stddev', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_2/beta', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_2/beta/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_2/beta/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_2/gamma', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_2/gamma/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_2/gamma/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_2/moving_mean', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_2/moving_stddev', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_2/moving_variance', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_2/renorm_mean', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_2/renorm_stddev', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_3/beta', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_3/beta/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_3/beta/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_3/gamma', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_3/gamma/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_3/gamma/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_3/moving_mean', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_3/moving_stddev', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_3/moving_variance', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_3/renorm_mean', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/BatchNorm_3/renorm_stddev', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d/bias', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d/bias/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d/bias/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d/kernel', [3, 3, 136, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d/kernel/Adam', [3, 3, 136, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d/kernel/Adam_1',\n",
       "  [3, 3, 136, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d_1/bias', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d_1/bias/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d_1/bias/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d_1/kernel', [3, 3, 264, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d_1/kernel/Adam',\n",
       "  [3, 3, 264, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d_1/kernel/Adam_1',\n",
       "  [3, 3, 264, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d_2/bias', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d_2/bias/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d_2/bias/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d_2/kernel', [3, 3, 392, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d_2/kernel/Adam',\n",
       "  [3, 3, 392, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d_2/kernel/Adam_1',\n",
       "  [3, 3, 392, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d_transpose/bias', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d_transpose/bias/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d_transpose/bias/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d_transpose/kernel',\n",
       "  [3, 3, 128, 520]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d_transpose/kernel/Adam',\n",
       "  [3, 3, 128, 520]),\n",
       " ('generator/g_deconv_layers/g_deconv0/conv2d_transpose/kernel/Adam_1',\n",
       "  [3, 3, 128, 520]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm/beta', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm/beta/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm/beta/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm/gamma', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm/gamma/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm/gamma/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm/moving_mean', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm/moving_stddev', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm/moving_variance', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm/renorm_mean', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm/renorm_stddev', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_1/beta', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_1/beta/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_1/beta/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_1/gamma', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_1/gamma/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_1/gamma/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_1/moving_mean', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_1/moving_stddev', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_1/moving_variance', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_1/renorm_mean', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_1/renorm_stddev', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_2/beta', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_2/beta/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_2/beta/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_2/gamma', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_2/gamma/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_2/gamma/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_2/moving_mean', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_2/moving_stddev', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_2/moving_variance', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_2/renorm_mean', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_2/renorm_stddev', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_3/beta', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_3/beta/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_3/beta/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_3/gamma', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_3/gamma/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_3/gamma/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_3/moving_mean', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_3/moving_stddev', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_3/moving_variance', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_3/renorm_mean', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/BatchNorm_3/renorm_stddev', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d/bias', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d/bias/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d/bias/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d/kernel', [3, 3, 388, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d/kernel/Adam', [3, 3, 388, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d/kernel/Adam_1',\n",
       "  [3, 3, 388, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_1/bias', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_1/bias/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_1/bias/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_1/kernel', [3, 3, 516, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_1/kernel/Adam',\n",
       "  [3, 3, 516, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_1/kernel/Adam_1',\n",
       "  [3, 3, 516, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_2/bias', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_2/bias/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_2/bias/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_2/kernel', [3, 3, 644, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_2/kernel/Adam',\n",
       "  [3, 3, 644, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_2/kernel/Adam_1',\n",
       "  [3, 3, 644, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose/bias', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose/bias/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose/bias/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose/kernel',\n",
       "  [3, 3, 128, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose/kernel/Adam',\n",
       "  [3, 3, 128, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose/kernel/Adam_1',\n",
       "  [3, 3, 128, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose_1/bias', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose_1/bias/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose_1/bias/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose_1/kernel',\n",
       "  [3, 3, 128, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose_1/kernel/Adam',\n",
       "  [3, 3, 128, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose_1/kernel/Adam_1',\n",
       "  [3, 3, 128, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose_2/bias', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose_2/bias/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose_2/bias/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose_2/kernel',\n",
       "  [3, 3, 128, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose_2/kernel/Adam',\n",
       "  [3, 3, 128, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose_2/kernel/Adam_1',\n",
       "  [3, 3, 128, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose_3/bias', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose_3/bias/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose_3/bias/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose_3/kernel',\n",
       "  [3, 3, 128, 644]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose_3/kernel/Adam',\n",
       "  [3, 3, 128, 644]),\n",
       " ('generator/g_deconv_layers/g_deconv1/conv2d_transpose_3/kernel/Adam_1',\n",
       "  [3, 3, 128, 644]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm/beta', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm/beta/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm/beta/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm/gamma', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm/gamma/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm/gamma/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm/moving_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm/moving_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm/moving_variance', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm/renorm_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm/renorm_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_1/beta', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_1/beta/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_1/beta/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_1/gamma', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_1/gamma/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_1/gamma/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_1/moving_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_1/moving_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_1/moving_variance', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_1/renorm_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_1/renorm_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_2/beta', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_2/beta/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_2/beta/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_2/gamma', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_2/gamma/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_2/gamma/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_2/moving_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_2/moving_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_2/moving_variance', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_2/renorm_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_2/renorm_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_3/beta', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_3/beta/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_3/beta/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_3/gamma', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_3/gamma/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_3/gamma/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_3/moving_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_3/moving_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_3/moving_variance', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_3/renorm_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/BatchNorm_3/renorm_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d/bias', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d/kernel', [3, 3, 322, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d/kernel/Adam', [3, 3, 322, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d/kernel/Adam_1', [3, 3, 322, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_1/bias', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_1/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_1/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_1/kernel', [3, 3, 386, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_1/kernel/Adam', [3, 3, 386, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_1/kernel/Adam_1',\n",
       "  [3, 3, 386, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_2/bias', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_2/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_2/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_2/kernel', [3, 3, 450, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_2/kernel/Adam', [3, 3, 450, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_2/kernel/Adam_1',\n",
       "  [3, 3, 450, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose/bias', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose/bias/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose/bias/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose/kernel',\n",
       "  [3, 3, 128, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose/kernel/Adam',\n",
       "  [3, 3, 128, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose/kernel/Adam_1',\n",
       "  [3, 3, 128, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose_1/bias', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose_1/bias/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose_1/bias/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose_1/kernel',\n",
       "  [3, 3, 128, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose_1/kernel/Adam',\n",
       "  [3, 3, 128, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose_1/kernel/Adam_1',\n",
       "  [3, 3, 128, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose_2/bias', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose_2/bias/Adam', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose_2/bias/Adam_1', [128]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose_2/kernel',\n",
       "  [3, 3, 128, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose_2/kernel/Adam',\n",
       "  [3, 3, 128, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose_2/kernel/Adam_1',\n",
       "  [3, 3, 128, 128]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose_3/bias', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose_3/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose_3/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose_3/kernel',\n",
       "  [3, 3, 64, 386]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose_3/kernel/Adam',\n",
       "  [3, 3, 64, 386]),\n",
       " ('generator/g_deconv_layers/g_deconv2/conv2d_transpose_3/kernel/Adam_1',\n",
       "  [3, 3, 64, 386]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm/beta', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm/beta/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm/beta/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm/gamma', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm/gamma/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm/gamma/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm/moving_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm/moving_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm/moving_variance', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm/renorm_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm/renorm_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_1/beta', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_1/beta/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_1/beta/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_1/gamma', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_1/gamma/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_1/gamma/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_1/moving_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_1/moving_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_1/moving_variance', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_1/renorm_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_1/renorm_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_2/beta', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_2/beta/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_2/beta/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_2/gamma', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_2/gamma/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_2/gamma/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_2/moving_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_2/moving_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_2/moving_variance', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_2/renorm_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_2/renorm_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_3/beta', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_3/beta/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_3/beta/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_3/gamma', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_3/gamma/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_3/gamma/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_3/moving_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_3/moving_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_3/moving_variance', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_3/renorm_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/BatchNorm_3/renorm_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d/bias', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d/kernel', [3, 3, 192, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d/kernel/Adam', [3, 3, 192, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d/kernel/Adam_1', [3, 3, 192, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_1/bias', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_1/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_1/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_1/kernel', [3, 3, 256, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_1/kernel/Adam', [3, 3, 256, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_1/kernel/Adam_1',\n",
       "  [3, 3, 256, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_2/bias', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_2/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_2/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_2/kernel', [3, 3, 320, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_2/kernel/Adam', [3, 3, 320, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_2/kernel/Adam_1',\n",
       "  [3, 3, 320, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose/bias', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose/kernel',\n",
       "  [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose/kernel/Adam',\n",
       "  [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose/kernel/Adam_1',\n",
       "  [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose_1/bias', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose_1/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose_1/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose_1/kernel',\n",
       "  [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose_1/kernel/Adam',\n",
       "  [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose_1/kernel/Adam_1',\n",
       "  [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose_2/bias', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose_2/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose_2/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose_2/kernel',\n",
       "  [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose_2/kernel/Adam',\n",
       "  [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose_2/kernel/Adam_1',\n",
       "  [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose_3/bias', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose_3/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose_3/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose_3/kernel',\n",
       "  [3, 3, 64, 320]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose_3/kernel/Adam',\n",
       "  [3, 3, 64, 320]),\n",
       " ('generator/g_deconv_layers/g_deconv3/conv2d_transpose_3/kernel/Adam_1',\n",
       "  [3, 3, 64, 320]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm/beta', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm/beta/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm/beta/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm/gamma', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm/gamma/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm/gamma/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm/moving_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm/moving_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm/moving_variance', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm/renorm_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm/renorm_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_1/beta', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_1/beta/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_1/beta/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_1/gamma', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_1/gamma/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_1/gamma/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_1/moving_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_1/moving_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_1/moving_variance', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_1/renorm_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_1/renorm_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_2/beta', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_2/beta/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_2/beta/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_2/gamma', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_2/gamma/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_2/gamma/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_2/moving_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_2/moving_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_2/moving_variance', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_2/renorm_mean', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/BatchNorm_2/renorm_stddev', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d/bias', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d/kernel', [3, 3, 129, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d/kernel/Adam', [3, 3, 129, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d/kernel/Adam_1', [3, 3, 129, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_1/bias', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_1/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_1/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_1/kernel', [3, 3, 193, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_1/kernel/Adam', [3, 3, 193, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_1/kernel/Adam_1',\n",
       "  [3, 3, 193, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_2/bias', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_2/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_2/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_2/kernel', [3, 3, 257, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_2/kernel/Adam', [3, 3, 257, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_2/kernel/Adam_1',\n",
       "  [3, 3, 257, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_transpose/bias', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_transpose/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_transpose/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_transpose/kernel',\n",
       "  [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_transpose/kernel/Adam',\n",
       "  [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_transpose/kernel/Adam_1',\n",
       "  [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_transpose_1/bias', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_transpose_1/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_transpose_1/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_transpose_1/kernel',\n",
       "  [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_transpose_1/kernel/Adam',\n",
       "  [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_transpose_1/kernel/Adam_1',\n",
       "  [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_transpose_2/bias', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_transpose_2/bias/Adam', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_transpose_2/bias/Adam_1', [64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_transpose_2/kernel',\n",
       "  [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_transpose_2/kernel/Adam',\n",
       "  [3, 3, 64, 64]),\n",
       " ('generator/g_deconv_layers/g_deconv4/conv2d_transpose_2/kernel/Adam_1',\n",
       "  [3, 3, 64, 64]),\n",
       " ('generator/vector_expansion/dense/bias', [32]),\n",
       " ('generator/vector_expansion/dense/bias/Adam', [32]),\n",
       " ('generator/vector_expansion/dense/bias/Adam_1', [32]),\n",
       " ('generator/vector_expansion/dense/kernel', [100, 32]),\n",
       " ('generator/vector_expansion/dense/kernel/Adam', [100, 32]),\n",
       " ('generator/vector_expansion/dense/kernel/Adam_1', [100, 32]),\n",
       " ('generator/vector_expansion/dense_1/bias', [64]),\n",
       " ('generator/vector_expansion/dense_1/bias/Adam', [64]),\n",
       " ('generator/vector_expansion/dense_1/bias/Adam_1', [64]),\n",
       " ('generator/vector_expansion/dense_1/kernel', [100, 64]),\n",
       " ('generator/vector_expansion/dense_1/kernel/Adam', [100, 64]),\n",
       " ('generator/vector_expansion/dense_1/kernel/Adam_1', [100, 64]),\n",
       " ('generator/vector_expansion/dense_2/bias', [98]),\n",
       " ('generator/vector_expansion/dense_2/bias/Adam', [98]),\n",
       " ('generator/vector_expansion/dense_2/bias/Adam_1', [98]),\n",
       " ('generator/vector_expansion/dense_2/kernel', [100, 98]),\n",
       " ('generator/vector_expansion/dense_2/kernel/Adam', [100, 98]),\n",
       " ('generator/vector_expansion/dense_2/kernel/Adam_1', [100, 98]),\n",
       " ('generator/vector_expansion/dense_3/bias', [196]),\n",
       " ('generator/vector_expansion/dense_3/kernel', [100, 196])]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_list = tf.train.list_variables(checkpoint)\n",
    "vars_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([520, 128, 3, 3])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape_conv(read_tf(\"generator/g_deconv_layers/g_deconv0/conv2d_transpose/kernel\")).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([386, 64, 3, 3])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_g.decode2.conv_t3.conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'TorchGAN' object has no attribute 'conv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-d4be34b223d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Workspace/pytorch/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    770\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 772\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'TorchGAN' object has no attribute 'conv'"
     ]
    }
   ],
   "source": [
    "torch_g.conv._modules['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_image_arr(raw_data[1200][0])\n",
    "render_image_arr(final_results[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.image.resize_nearest_neighbor(inp, (None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
