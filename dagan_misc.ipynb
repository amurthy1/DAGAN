{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import slim\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "import torchvision.transforms as transforms\n",
    "from old_generator import TorchGAN\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(\"gdown --id 1TE1Bi5ym-TbLSnlkAAOP0sSQYkgTNl4A --output datasets/omniglot_data.npy\")\n",
    "# os.system(\"mkdir checkpoints\")\n",
    "# os.system(\"gdown --id 1qw_op6L2RebrGik0cBWquDK3RTculrVR --output checkpoints/model.ckpt.data-00000-of-00001\")\n",
    "# os.system(\"gdown --id 17UFRFwWOyJ_-tU72SH0o5mrg2-oEra95 --output checkpoints/model.ckpt.index\")\n",
    "# os.system(\"gdown --id 1iSOAjMUWLDemHljNHk0grCFdblSArBcP --output checkpoints/model.ckpt.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.ones((1, 100)) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = np.load(\"datasets/omniglot_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.array([raw_data[1200][0]], dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dagan_architectures import UResNetGenerator, Discriminator\n",
    "\n",
    "g = UResNetGenerator(batch_size=1, layer_sizes=[64, 64, 128, 128], layer_padding=None,\n",
    "                        inner_layers=[3] * 4, name=\"generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_inp = tf.placeholder(tf.float32, [1,100], 'z-inp')\n",
    "cond_inp = tf.placeholder(tf.float32, [1,28,28,1], 'cond-inp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ashwin/Workspace/DAGAN/dagan_architectures.py:217: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/ashwin/Workspace/DAGAN/dagan_architectures.py:78: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /Library/Python/3.7/site-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /Users/ashwin/Workspace/DAGAN/dagan_architectures.py:135: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /Users/ashwin/Workspace/DAGAN/dagan_architectures.py:271: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "Tensor(\"generator/vector_expansion/Reshape:0\", shape=(1, 2, 2, 8), dtype=float32)\n",
      "Tensor(\"generator/vector_expansion/Reshape_1:0\", shape=(1, 4, 4, 4), dtype=float32)\n",
      "Tensor(\"generator/vector_expansion/Reshape_2:0\", shape=(1, 7, 7, 2), dtype=float32)\n",
      "Tensor(\"generator/vector_expansion/Reshape_3:0\", shape=(1, 14, 14, 1), dtype=float32)\n",
      "WARNING:tensorflow:From /Users/ashwin/Workspace/DAGAN/dagan_architectures.py:54: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/ashwin/Workspace/DAGAN/dagan_architectures.py:75: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "WARNING:tensorflow:From /Users/ashwin/Workspace/DAGAN/dagan_architectures.py:361: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/ashwin/Workspace/DAGAN/dagan_architectures.py:361: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "generator_total_layers 50\n",
      "generator_parameter_num 10546217\n"
     ]
    }
   ],
   "source": [
    "result = g(z_inp, cond_inp, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchGAN(\n",
       "  (encode0): Sequential(\n",
       "    (pad): _SamePad()\n",
       "    (conv): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (relu): LeakyReLU(negative_slope=0.2)\n",
       "    (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (encode1): _EncoderBlock(\n",
       "    (pre_conv): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(1, 1, kernel_size=(3, 3), stride=(2, 2))\n",
       "    )\n",
       "    (conv0): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (encode2): _EncoderBlock(\n",
       "    (pre_conv): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    )\n",
       "    (conv0): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(320, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(448, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (encode3): _EncoderBlock(\n",
       "    (pre_conv): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    )\n",
       "    (conv0): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (z_reshape0): Linear(in_features=100, out_features=32, bias=True)\n",
       "  (z_reshape1): Linear(in_features=100, out_features=64, bias=True)\n",
       "  (z_reshape2): Linear(in_features=100, out_features=98, bias=True)\n",
       "  (decode0): _DecoderBlock(\n",
       "    (conv0): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(136, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(264, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(392, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_t3): Sequential(\n",
       "      (upsample): Upsample(size=4, mode=nearest)\n",
       "      (conv): ConvTranspose2d(520, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (decode1): _DecoderBlock(\n",
       "    (pre_conv_t0): Sequential(\n",
       "      (upsample): Upsample(size=4, mode=nearest)\n",
       "      (conv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv0): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(388, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pre_conv_t1): Sequential(\n",
       "      (upsample): Upsample(size=4, mode=nearest)\n",
       "      (conv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(516, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pre_conv_t2): Sequential(\n",
       "      (upsample): Upsample(size=4, mode=nearest)\n",
       "      (conv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(644, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_t3): Sequential(\n",
       "      (upsample): Upsample(size=7, mode=nearest)\n",
       "      (conv): ConvTranspose2d(644, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (decode2): _DecoderBlock(\n",
       "    (pre_conv_t0): Sequential(\n",
       "      (upsample): Upsample(size=7, mode=nearest)\n",
       "      (conv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv0): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(322, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pre_conv_t1): Sequential(\n",
       "      (upsample): Upsample(size=7, mode=nearest)\n",
       "      (conv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(386, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pre_conv_t2): Sequential(\n",
       "      (upsample): Upsample(size=7, mode=nearest)\n",
       "      (conv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(450, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_t3): Sequential(\n",
       "      (upsample): Upsample(size=14, mode=nearest)\n",
       "      (conv): ConvTranspose2d(386, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (decode3): _DecoderBlock(\n",
       "    (pre_conv_t0): Sequential(\n",
       "      (upsample): Upsample(size=14, mode=nearest)\n",
       "      (conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv0): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pre_conv_t1): Sequential(\n",
       "      (upsample): Upsample(size=14, mode=nearest)\n",
       "      (conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pre_conv_t2): Sequential(\n",
       "      (upsample): Upsample(size=14, mode=nearest)\n",
       "      (conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_t3): Sequential(\n",
       "      (upsample): Upsample(size=28, mode=nearest)\n",
       "      (conv): ConvTranspose2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (decode4): _DecoderBlock(\n",
       "    (pre_conv_t0): Sequential(\n",
       "      (upsample): Upsample(size=28, mode=nearest)\n",
       "      (conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv0): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(129, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pre_conv_t1): Sequential(\n",
       "      (upsample): Upsample(size=28, mode=nearest)\n",
       "      (conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(193, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pre_conv_t2): Sequential(\n",
       "      (upsample): Upsample(size=28, mode=nearest)\n",
       "      (conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (pad): _SamePad()\n",
       "      (conv): Conv2d(257, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): LeakyReLU(negative_slope=0.2)\n",
       "      (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (final_conv0): Sequential(\n",
       "    (pad): _SamePad()\n",
       "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (relu): LeakyReLU(negative_slope=0.2)\n",
       "    (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (final_conv1): Sequential(\n",
       "    (pad): _SamePad()\n",
       "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (relu): LeakyReLU(negative_slope=0.2)\n",
       "    (batchnorm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (final_conv2): Sequential(\n",
       "    (pad): _SamePad()\n",
       "    (conv): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_g = TorchGAN(dim=28, channels=1)\n",
    "torch_g.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"checkpoints/checkpoint.ckpt\"\n",
    "ckpt_reader = tf.train.load_checkpoint(checkpoint)\n",
    "def read_tf(var):\n",
    "    return torch.tensor(ckpt_reader.get_tensor(var))\n",
    "\n",
    "def reshape_conv(tensor):\n",
    "    return tensor.transpose(0, 3).transpose(1, 2).transpose(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed torch generator weights\n",
    "\n",
    "def convert_conv_layer(torch_layer, conv_path, bn_path=None):\n",
    "    if bn_path is not None:\n",
    "        torch_layer.batchnorm.weight.data = read_tf(bn_path + \"/gamma\")\n",
    "        torch_layer.batchnorm.bias.data = read_tf(bn_path + \"/beta\")\n",
    "        torch_layer.batchnorm.running_mean = read_tf(bn_path + \"/moving_mean\")\n",
    "        torch_layer.batchnorm.running_var = read_tf(bn_path + \"/moving_variance\")\n",
    "    \n",
    "    torch_layer.conv.weight.data = reshape_conv(read_tf(conv_path + \"/kernel\"))\n",
    "    torch_layer.conv.bias.data = read_tf(conv_path + \"/bias\")\n",
    "    \n",
    "num_layers = torch_g.num_inner_layers\n",
    "\n",
    "# Encoders\n",
    "convert_conv_layer(\n",
    "    torch_g.encode0, \"generator/conv_layers/g_conv0/conv2d\", \"generator/conv_layers/g_conv0/BatchNorm\")\n",
    "\n",
    "for i in range(1, torch_g.U_depth):\n",
    "    module = torch_g._modules[\"encode%d\" % i]\n",
    "    convert_conv_layer(\n",
    "        module.pre_conv,\n",
    "        f\"generator/conv_layers/g_conv{i}/conv2d\"\n",
    "    )\n",
    "\n",
    "    for j in range(num_layers + 1):\n",
    "        bn_suffix = f\"_{j}\" if j > 0 else \"\"\n",
    "        convert_conv_layer(\n",
    "            module._modules[f\"conv{j}\"],\n",
    "            f\"generator/conv_layers/g_conv{i}/conv2d_{j + 1}\",\n",
    "            f\"generator/conv_layers/g_conv{i}/BatchNorm{bn_suffix}\",\n",
    "        )\n",
    "\n",
    "# Noise encoders\n",
    "for i in range(torch_g.noise_encoders):\n",
    "    module = torch_g._modules[\"z_reshape%d\" % i]\n",
    "    z_suffix = f\"_{i}\" if i > 0 else \"\"\n",
    "    module.weight.data = read_tf(f\"generator/vector_expansion/dense{z_suffix}/kernel\").T\n",
    "    module.bias.data = read_tf(f\"generator/vector_expansion/dense{z_suffix}/bias\").T\n",
    "\n",
    "\n",
    "# Decoders\n",
    "for i in range(torch_g.U_depth + 1):\n",
    "    module = torch_g._modules[\"decode%d\" % i]\n",
    "\n",
    "    for j in range(num_layers):\n",
    "        idx_suffix = f\"_{j}\" if j > 0 else \"\"\n",
    "        if i > 0:\n",
    "            convert_conv_layer(\n",
    "                module._modules[f\"pre_conv_t{j}\"],\n",
    "                f\"generator/g_deconv_layers/g_deconv{i}/conv2d_transpose{idx_suffix}\",\n",
    "            )\n",
    "        convert_conv_layer(\n",
    "            module._modules[f\"conv{j}\"],\n",
    "            f\"generator/g_deconv_layers/g_deconv{i}/conv2d{idx_suffix}\",\n",
    "            f\"generator/g_deconv_layers/g_deconv{i}/BatchNorm{idx_suffix}\",\n",
    "        )\n",
    "    if i < torch_g.U_depth:\n",
    "        conv_suffix = f\"_{num_layers}\" if i > 0 else \"\"\n",
    "        convert_conv_layer(\n",
    "            module._modules[f\"conv_t{num_layers}\"],\n",
    "            f\"generator/g_deconv_layers/g_deconv{i}/conv2d_transpose{conv_suffix}\",\n",
    "            f\"generator/g_deconv_layers/g_deconv{i}/BatchNorm_{num_layers}\",\n",
    "        )\n",
    "        \n",
    "# Final conv\n",
    "for i in range(torch_g.num_final_conv):\n",
    "    idx_suffix = f\"_{i}\" if i > 0 else \"\"\n",
    "    if i == torch_g.num_final_conv - 1:\n",
    "        bn_path = None\n",
    "    else:\n",
    "        bn_path = f\"generator/g_deconv_layers/BatchNorm{idx_suffix}\"\n",
    "    convert_conv_layer(\n",
    "        torch_g._modules[f\"final_conv{i}\"],\n",
    "        f\"generator/g_deconv_layers/conv2d{idx_suffix}\",\n",
    "        bn_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/checkpoint.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.9968462 ],\n",
       "         [ 0.9989222 ],\n",
       "         [ 0.99855083],\n",
       "         [ 0.9990234 ],\n",
       "         [ 0.99923205],\n",
       "         [ 0.99925864],\n",
       "         [ 0.999233  ],\n",
       "         [ 0.99920547],\n",
       "         [ 0.99920064],\n",
       "         [ 0.99921155],\n",
       "         [ 0.99922633],\n",
       "         [ 0.9992216 ],\n",
       "         [ 0.9991688 ],\n",
       "         [ 0.99908626],\n",
       "         [ 0.9989827 ],\n",
       "         [ 0.9989365 ],\n",
       "         [ 0.99896497],\n",
       "         [ 0.99904543],\n",
       "         [ 0.9991413 ],\n",
       "         [ 0.99921304],\n",
       "         [ 0.9992914 ],\n",
       "         [ 0.99936825],\n",
       "         [ 0.9993983 ],\n",
       "         [ 0.999387  ],\n",
       "         [ 0.99926925],\n",
       "         [ 0.99922645],\n",
       "         [ 0.9995618 ],\n",
       "         [ 0.9982861 ]],\n",
       "\n",
       "        [[ 0.99911857],\n",
       "         [ 0.9995758 ],\n",
       "         [ 0.9996732 ],\n",
       "         [ 0.99970555],\n",
       "         [ 0.9996501 ],\n",
       "         [ 0.9996456 ],\n",
       "         [ 0.9996344 ],\n",
       "         [ 0.9996166 ],\n",
       "         [ 0.99958926],\n",
       "         [ 0.9996042 ],\n",
       "         [ 0.99962914],\n",
       "         [ 0.99967337],\n",
       "         [ 0.9996983 ],\n",
       "         [ 0.9996926 ],\n",
       "         [ 0.9996852 ],\n",
       "         [ 0.99968594],\n",
       "         [ 0.99969023],\n",
       "         [ 0.99969697],\n",
       "         [ 0.9996909 ],\n",
       "         [ 0.9996857 ],\n",
       "         [ 0.9996923 ],\n",
       "         [ 0.99971974],\n",
       "         [ 0.99974966],\n",
       "         [ 0.99978775],\n",
       "         [ 0.99978715],\n",
       "         [ 0.99982905],\n",
       "         [ 0.99992347],\n",
       "         [ 0.9998011 ]],\n",
       "\n",
       "        [[ 0.9993862 ],\n",
       "         [ 0.99944896],\n",
       "         [ 0.99918836],\n",
       "         [ 0.99899143],\n",
       "         [ 0.99894613],\n",
       "         [ 0.99890906],\n",
       "         [ 0.99880457],\n",
       "         [ 0.99873894],\n",
       "         [ 0.9987251 ],\n",
       "         [ 0.998823  ],\n",
       "         [ 0.9988968 ],\n",
       "         [ 0.99900997],\n",
       "         [ 0.9991081 ],\n",
       "         [ 0.9991452 ],\n",
       "         [ 0.999161  ],\n",
       "         [ 0.9991909 ],\n",
       "         [ 0.99917287],\n",
       "         [ 0.99916136],\n",
       "         [ 0.9991371 ],\n",
       "         [ 0.9990975 ],\n",
       "         [ 0.9990503 ],\n",
       "         [ 0.9990917 ],\n",
       "         [ 0.9991522 ],\n",
       "         [ 0.99928904],\n",
       "         [ 0.99924606],\n",
       "         [ 0.99940264],\n",
       "         [ 0.99987525],\n",
       "         [ 0.9999105 ]],\n",
       "\n",
       "        [[ 0.99970245],\n",
       "         [ 0.9997154 ],\n",
       "         [ 0.999252  ],\n",
       "         [ 0.99929917],\n",
       "         [ 0.9993683 ],\n",
       "         [ 0.9993429 ],\n",
       "         [ 0.9992643 ],\n",
       "         [ 0.99920607],\n",
       "         [ 0.9992116 ],\n",
       "         [ 0.9992703 ],\n",
       "         [ 0.9992791 ],\n",
       "         [ 0.9993155 ],\n",
       "         [ 0.99935   ],\n",
       "         [ 0.99934983],\n",
       "         [ 0.9993723 ],\n",
       "         [ 0.9994113 ],\n",
       "         [ 0.9994269 ],\n",
       "         [ 0.9994758 ],\n",
       "         [ 0.9995194 ],\n",
       "         [ 0.99955106],\n",
       "         [ 0.9995383 ],\n",
       "         [ 0.99954075],\n",
       "         [ 0.9995553 ],\n",
       "         [ 0.9996122 ],\n",
       "         [ 0.99954367],\n",
       "         [ 0.9996562 ],\n",
       "         [ 0.9999125 ],\n",
       "         [ 0.99996245]],\n",
       "\n",
       "        [[ 0.99973035],\n",
       "         [ 0.99974346],\n",
       "         [ 0.99908805],\n",
       "         [ 0.9991584 ],\n",
       "         [ 0.9992642 ],\n",
       "         [ 0.99922943],\n",
       "         [ 0.99912125],\n",
       "         [ 0.9990707 ],\n",
       "         [ 0.9991194 ],\n",
       "         [ 0.99919134],\n",
       "         [ 0.9992442 ],\n",
       "         [ 0.9993373 ],\n",
       "         [ 0.9993515 ],\n",
       "         [ 0.99922305],\n",
       "         [ 0.9991913 ],\n",
       "         [ 0.9992318 ],\n",
       "         [ 0.9991993 ],\n",
       "         [ 0.9991913 ],\n",
       "         [ 0.9991942 ],\n",
       "         [ 0.99920547],\n",
       "         [ 0.99915904],\n",
       "         [ 0.9991689 ],\n",
       "         [ 0.9992429 ],\n",
       "         [ 0.9994013 ],\n",
       "         [ 0.9993566 ],\n",
       "         [ 0.99951833],\n",
       "         [ 0.99991935],\n",
       "         [ 0.9999803 ]],\n",
       "\n",
       "        [[ 0.99971473],\n",
       "         [ 0.9996919 ],\n",
       "         [ 0.99910396],\n",
       "         [ 0.99913895],\n",
       "         [ 0.99909586],\n",
       "         [ 0.998763  ],\n",
       "         [ 0.9984763 ],\n",
       "         [ 0.9983365 ],\n",
       "         [ 0.99836886],\n",
       "         [ 0.9986736 ],\n",
       "         [ 0.9989437 ],\n",
       "         [ 0.99932486],\n",
       "         [ 0.99943364],\n",
       "         [ 0.99911326],\n",
       "         [ 0.998549  ],\n",
       "         [ 0.9983461 ],\n",
       "         [ 0.9987951 ],\n",
       "         [ 0.99914247],\n",
       "         [ 0.9992601 ],\n",
       "         [ 0.9993131 ],\n",
       "         [ 0.9993002 ],\n",
       "         [ 0.99932337],\n",
       "         [ 0.9993892 ],\n",
       "         [ 0.99951553],\n",
       "         [ 0.99945354],\n",
       "         [ 0.99953884],\n",
       "         [ 0.99992645],\n",
       "         [ 0.99998754]],\n",
       "\n",
       "        [[ 0.99964976],\n",
       "         [ 0.99965143],\n",
       "         [ 0.9991799 ],\n",
       "         [ 0.9992053 ],\n",
       "         [ 0.9987565 ],\n",
       "         [ 0.9962369 ],\n",
       "         [ 0.9807135 ],\n",
       "         [ 0.9595077 ],\n",
       "         [ 0.9408782 ],\n",
       "         [ 0.9068808 ],\n",
       "         [ 0.89352524],\n",
       "         [ 0.8774075 ],\n",
       "         [ 0.79598373],\n",
       "         [ 0.6725246 ],\n",
       "         [ 0.49044794],\n",
       "         [ 0.7030348 ],\n",
       "         [ 0.9692913 ],\n",
       "         [ 0.9972705 ],\n",
       "         [ 0.9990185 ],\n",
       "         [ 0.99924874],\n",
       "         [ 0.99928486],\n",
       "         [ 0.9993025 ],\n",
       "         [ 0.99935406],\n",
       "         [ 0.9994766 ],\n",
       "         [ 0.99937916],\n",
       "         [ 0.9994685 ],\n",
       "         [ 0.999931  ],\n",
       "         [ 0.9999911 ]],\n",
       "\n",
       "        [[ 0.9996358 ],\n",
       "         [ 0.99972165],\n",
       "         [ 0.99933195],\n",
       "         [ 0.99927235],\n",
       "         [ 0.9983992 ],\n",
       "         [ 0.9793554 ],\n",
       "         [ 0.35266387],\n",
       "         [-0.50450444],\n",
       "         [-0.5938313 ],\n",
       "         [-0.6214046 ],\n",
       "         [-0.63276005],\n",
       "         [-0.6719487 ],\n",
       "         [-0.7062752 ],\n",
       "         [-0.7670922 ],\n",
       "         [-0.7419491 ],\n",
       "         [-0.02374439],\n",
       "         [ 0.93425786],\n",
       "         [ 0.99687856],\n",
       "         [ 0.9991396 ],\n",
       "         [ 0.9993736 ],\n",
       "         [ 0.9994215 ],\n",
       "         [ 0.99942935],\n",
       "         [ 0.9994608 ],\n",
       "         [ 0.9995628 ],\n",
       "         [ 0.9994176 ],\n",
       "         [ 0.9994838 ],\n",
       "         [ 0.9999373 ],\n",
       "         [ 0.99999285]],\n",
       "\n",
       "        [[ 0.99963105],\n",
       "         [ 0.9997205 ],\n",
       "         [ 0.9991954 ],\n",
       "         [ 0.99912393],\n",
       "         [ 0.99841976],\n",
       "         [ 0.9845041 ],\n",
       "         [ 0.63660294],\n",
       "         [ 0.16673705],\n",
       "         [ 0.08816644],\n",
       "         [ 0.03107047],\n",
       "         [ 0.09162036],\n",
       "         [ 0.20254335],\n",
       "         [ 0.29902482],\n",
       "         [ 0.40344077],\n",
       "         [ 0.5271356 ],\n",
       "         [ 0.8189446 ],\n",
       "         [ 0.9834984 ],\n",
       "         [ 0.99785984],\n",
       "         [ 0.9990229 ],\n",
       "         [ 0.9992404 ],\n",
       "         [ 0.99929273],\n",
       "         [ 0.9993028 ],\n",
       "         [ 0.99933946],\n",
       "         [ 0.9994833 ],\n",
       "         [ 0.99931705],\n",
       "         [ 0.99943966],\n",
       "         [ 0.9999422 ],\n",
       "         [ 0.99999404]],\n",
       "\n",
       "        [[ 0.99963146],\n",
       "         [ 0.99978656],\n",
       "         [ 0.9993201 ],\n",
       "         [ 0.99923253],\n",
       "         [ 0.9992595 ],\n",
       "         [ 0.99875546],\n",
       "         [ 0.9937846 ],\n",
       "         [ 0.9886164 ],\n",
       "         [ 0.9920884 ],\n",
       "         [ 0.9942149 ],\n",
       "         [ 0.9953466 ],\n",
       "         [ 0.9963252 ],\n",
       "         [ 0.99755096],\n",
       "         [ 0.9984733 ],\n",
       "         [ 0.9989283 ],\n",
       "         [ 0.99897265],\n",
       "         [ 0.99910295],\n",
       "         [ 0.9991696 ],\n",
       "         [ 0.99916136],\n",
       "         [ 0.999234  ],\n",
       "         [ 0.99928   ],\n",
       "         [ 0.99930894],\n",
       "         [ 0.99937445],\n",
       "         [ 0.9995248 ],\n",
       "         [ 0.99935156],\n",
       "         [ 0.99946207],\n",
       "         [ 0.9999466 ],\n",
       "         [ 0.9999948 ]],\n",
       "\n",
       "        [[ 0.9995958 ],\n",
       "         [ 0.99976134],\n",
       "         [ 0.9992727 ],\n",
       "         [ 0.999156  ],\n",
       "         [ 0.99919796],\n",
       "         [ 0.9983399 ],\n",
       "         [ 0.9938806 ],\n",
       "         [ 0.99548787],\n",
       "         [ 0.9988797 ],\n",
       "         [ 0.99950874],\n",
       "         [ 0.9995344 ],\n",
       "         [ 0.9994735 ],\n",
       "         [ 0.9993417 ],\n",
       "         [ 0.9992742 ],\n",
       "         [ 0.9992462 ],\n",
       "         [ 0.99916583],\n",
       "         [ 0.99909294],\n",
       "         [ 0.999071  ],\n",
       "         [ 0.9990645 ],\n",
       "         [ 0.999141  ],\n",
       "         [ 0.9991489 ],\n",
       "         [ 0.9991818 ],\n",
       "         [ 0.99927825],\n",
       "         [ 0.99945235],\n",
       "         [ 0.99924684],\n",
       "         [ 0.9994017 ],\n",
       "         [ 0.9999512 ],\n",
       "         [ 0.99999565]],\n",
       "\n",
       "        [[ 0.9995597 ],\n",
       "         [ 0.99971896],\n",
       "         [ 0.99922144],\n",
       "         [ 0.99916863],\n",
       "         [ 0.9991308 ],\n",
       "         [ 0.99494606],\n",
       "         [ 0.95368147],\n",
       "         [ 0.9676563 ],\n",
       "         [ 0.99822813],\n",
       "         [ 0.9993228 ],\n",
       "         [ 0.9990366 ],\n",
       "         [ 0.9986492 ],\n",
       "         [ 0.99836934],\n",
       "         [ 0.9985299 ],\n",
       "         [ 0.9989078 ],\n",
       "         [ 0.9990721 ],\n",
       "         [ 0.99909276],\n",
       "         [ 0.99901366],\n",
       "         [ 0.9990036 ],\n",
       "         [ 0.9991263 ],\n",
       "         [ 0.9991311 ],\n",
       "         [ 0.99917996],\n",
       "         [ 0.99929464],\n",
       "         [ 0.9994623 ],\n",
       "         [ 0.99924004],\n",
       "         [ 0.9993881 ],\n",
       "         [ 0.99995524],\n",
       "         [ 0.99999636]],\n",
       "\n",
       "        [[ 0.9995554 ],\n",
       "         [ 0.99971366],\n",
       "         [ 0.99925774],\n",
       "         [ 0.9992404 ],\n",
       "         [ 0.9990621 ],\n",
       "         [ 0.98932767],\n",
       "         [ 0.74391675],\n",
       "         [ 0.8131818 ],\n",
       "         [ 0.9964709 ],\n",
       "         [ 0.99932826],\n",
       "         [ 0.99912995],\n",
       "         [ 0.9987971 ],\n",
       "         [ 0.9986253 ],\n",
       "         [ 0.9988782 ],\n",
       "         [ 0.99920875],\n",
       "         [ 0.9991945 ],\n",
       "         [ 0.9991116 ],\n",
       "         [ 0.99893594],\n",
       "         [ 0.9989738 ],\n",
       "         [ 0.9991432 ],\n",
       "         [ 0.99910194],\n",
       "         [ 0.99913996],\n",
       "         [ 0.999276  ],\n",
       "         [ 0.99945116],\n",
       "         [ 0.99919826],\n",
       "         [ 0.99938196],\n",
       "         [ 0.99995947],\n",
       "         [ 0.99999696]],\n",
       "\n",
       "        [[ 0.99956757],\n",
       "         [ 0.9997099 ],\n",
       "         [ 0.9992782 ],\n",
       "         [ 0.9992951 ],\n",
       "         [ 0.99920654],\n",
       "         [ 0.9925928 ],\n",
       "         [ 0.6233228 ],\n",
       "         [ 0.42227802],\n",
       "         [ 0.96772224],\n",
       "         [ 0.9987589 ],\n",
       "         [ 0.99924266],\n",
       "         [ 0.9992654 ],\n",
       "         [ 0.99913365],\n",
       "         [ 0.9992171 ],\n",
       "         [ 0.99925303],\n",
       "         [ 0.9988987 ],\n",
       "         [ 0.99876827],\n",
       "         [ 0.9987153 ],\n",
       "         [ 0.9990133 ],\n",
       "         [ 0.99919504],\n",
       "         [ 0.9991202 ],\n",
       "         [ 0.99915004],\n",
       "         [ 0.99927974],\n",
       "         [ 0.99945265],\n",
       "         [ 0.99918836],\n",
       "         [ 0.99943066],\n",
       "         [ 0.99996454],\n",
       "         [ 0.99999744]],\n",
       "\n",
       "        [[ 0.99957913],\n",
       "         [ 0.9997153 ],\n",
       "         [ 0.999276  ],\n",
       "         [ 0.9992787 ],\n",
       "         [ 0.99936783],\n",
       "         [ 0.9978896 ],\n",
       "         [ 0.74811226],\n",
       "         [-0.42599195],\n",
       "         [ 0.2018568 ],\n",
       "         [ 0.9686024 ],\n",
       "         [ 0.9986476 ],\n",
       "         [ 0.9992701 ],\n",
       "         [ 0.99930465],\n",
       "         [ 0.999227  ],\n",
       "         [ 0.99861413],\n",
       "         [ 0.9947404 ],\n",
       "         [ 0.9934197 ],\n",
       "         [ 0.9971074 ],\n",
       "         [ 0.99909854],\n",
       "         [ 0.9992869 ],\n",
       "         [ 0.99914867],\n",
       "         [ 0.99917763],\n",
       "         [ 0.999294  ],\n",
       "         [ 0.9994615 ],\n",
       "         [ 0.99920046],\n",
       "         [ 0.99946404],\n",
       "         [ 0.9999671 ],\n",
       "         [ 0.9999977 ]],\n",
       "\n",
       "        [[ 0.99960524],\n",
       "         [ 0.9997155 ],\n",
       "         [ 0.9992483 ],\n",
       "         [ 0.99920017],\n",
       "         [ 0.9993471 ],\n",
       "         [ 0.99928325],\n",
       "         [ 0.9835167 ],\n",
       "         [ 0.16709824],\n",
       "         [-0.74976474],\n",
       "         [-0.09392604],\n",
       "         [ 0.6504638 ],\n",
       "         [ 0.9016165 ],\n",
       "         [ 0.9410581 ],\n",
       "         [ 0.8997697 ],\n",
       "         [ 0.7526972 ],\n",
       "         [ 0.4395245 ],\n",
       "         [ 0.5195396 ],\n",
       "         [ 0.95578396],\n",
       "         [ 0.99791884],\n",
       "         [ 0.99919444],\n",
       "         [ 0.99918187],\n",
       "         [ 0.99916935],\n",
       "         [ 0.999251  ],\n",
       "         [ 0.9994216 ],\n",
       "         [ 0.99914354],\n",
       "         [ 0.99944896],\n",
       "         [ 0.9999679 ],\n",
       "         [ 0.99999785]],\n",
       "\n",
       "        [[ 0.9996294 ],\n",
       "         [ 0.99972594],\n",
       "         [ 0.9992266 ],\n",
       "         [ 0.99915916],\n",
       "         [ 0.999213  ],\n",
       "         [ 0.9994216 ],\n",
       "         [ 0.99891293],\n",
       "         [ 0.9476565 ],\n",
       "         [ 0.11573607],\n",
       "         [-0.7866297 ],\n",
       "         [-0.7299901 ],\n",
       "         [-0.5551819 ],\n",
       "         [-0.5093948 ],\n",
       "         [-0.59175205],\n",
       "         [-0.7129443 ],\n",
       "         [-0.8356149 ],\n",
       "         [-0.27758121],\n",
       "         [ 0.90566534],\n",
       "         [ 0.9966153 ],\n",
       "         [ 0.9990757 ],\n",
       "         [ 0.9991482 ],\n",
       "         [ 0.9991541 ],\n",
       "         [ 0.9992454 ],\n",
       "         [ 0.99942756],\n",
       "         [ 0.9991584 ],\n",
       "         [ 0.999455  ],\n",
       "         [ 0.999968  ],\n",
       "         [ 0.99999785]],\n",
       "\n",
       "        [[ 0.9996543 ],\n",
       "         [ 0.9997367 ],\n",
       "         [ 0.9992195 ],\n",
       "         [ 0.99912596],\n",
       "         [ 0.9991142 ],\n",
       "         [ 0.99918306],\n",
       "         [ 0.99937415],\n",
       "         [ 0.9985467 ],\n",
       "         [ 0.9713622 ],\n",
       "         [ 0.672674  ],\n",
       "         [ 0.37347293],\n",
       "         [ 0.13479075],\n",
       "         [ 0.11617879],\n",
       "         [ 0.22431   ],\n",
       "         [ 0.3748563 ],\n",
       "         [ 0.5332727 ],\n",
       "         [ 0.81579655],\n",
       "         [ 0.9874528 ],\n",
       "         [ 0.99856335],\n",
       "         [ 0.9991954 ],\n",
       "         [ 0.99911165],\n",
       "         [ 0.9990857 ],\n",
       "         [ 0.99917203],\n",
       "         [ 0.9993664 ],\n",
       "         [ 0.9990845 ],\n",
       "         [ 0.9994283 ],\n",
       "         [ 0.9999676 ],\n",
       "         [ 0.99999774]],\n",
       "\n",
       "        [[ 0.9996473 ],\n",
       "         [ 0.9997083 ],\n",
       "         [ 0.9991661 ],\n",
       "         [ 0.9990886 ],\n",
       "         [ 0.99907535],\n",
       "         [ 0.99908906],\n",
       "         [ 0.9991163 ],\n",
       "         [ 0.99933434],\n",
       "         [ 0.99934494],\n",
       "         [ 0.99864966],\n",
       "         [ 0.9969672 ],\n",
       "         [ 0.9951123 ],\n",
       "         [ 0.9943316 ],\n",
       "         [ 0.99433106],\n",
       "         [ 0.9944974 ],\n",
       "         [ 0.9962972 ],\n",
       "         [ 0.9980343 ],\n",
       "         [ 0.99902695],\n",
       "         [ 0.9992315 ],\n",
       "         [ 0.99917346],\n",
       "         [ 0.9990795 ],\n",
       "         [ 0.99909174],\n",
       "         [ 0.99915916],\n",
       "         [ 0.9993514 ],\n",
       "         [ 0.99904996],\n",
       "         [ 0.9994204 ],\n",
       "         [ 0.9999686 ],\n",
       "         [ 0.9999979 ]],\n",
       "\n",
       "        [[ 0.99966544],\n",
       "         [ 0.9997177 ],\n",
       "         [ 0.99924684],\n",
       "         [ 0.9991411 ],\n",
       "         [ 0.99912125],\n",
       "         [ 0.9991502 ],\n",
       "         [ 0.9990873 ],\n",
       "         [ 0.9991429 ],\n",
       "         [ 0.9993003 ],\n",
       "         [ 0.99943227],\n",
       "         [ 0.9995259 ],\n",
       "         [ 0.9994878 ],\n",
       "         [ 0.99941665],\n",
       "         [ 0.99934953],\n",
       "         [ 0.99935275],\n",
       "         [ 0.99936885],\n",
       "         [ 0.9993551 ],\n",
       "         [ 0.99929476],\n",
       "         [ 0.99921495],\n",
       "         [ 0.9992489 ],\n",
       "         [ 0.99921525],\n",
       "         [ 0.9991984 ],\n",
       "         [ 0.9992203 ],\n",
       "         [ 0.9993826 ],\n",
       "         [ 0.9990864 ],\n",
       "         [ 0.99943435],\n",
       "         [ 0.99996895],\n",
       "         [ 0.99999803]],\n",
       "\n",
       "        [[ 0.9996326 ],\n",
       "         [ 0.9996472 ],\n",
       "         [ 0.99912155],\n",
       "         [ 0.9989907 ],\n",
       "         [ 0.9989267 ],\n",
       "         [ 0.99894357],\n",
       "         [ 0.9988826 ],\n",
       "         [ 0.9988687 ],\n",
       "         [ 0.99889636],\n",
       "         [ 0.99897593],\n",
       "         [ 0.99906194],\n",
       "         [ 0.99904007],\n",
       "         [ 0.99889666],\n",
       "         [ 0.9987566 ],\n",
       "         [ 0.9988048 ],\n",
       "         [ 0.9989279 ],\n",
       "         [ 0.99900174],\n",
       "         [ 0.99905694],\n",
       "         [ 0.99910015],\n",
       "         [ 0.99919045],\n",
       "         [ 0.9991437 ],\n",
       "         [ 0.99905425],\n",
       "         [ 0.9990503 ],\n",
       "         [ 0.9992657 ],\n",
       "         [ 0.9989133 ],\n",
       "         [ 0.9993347 ],\n",
       "         [ 0.9999666 ],\n",
       "         [ 0.99999785]],\n",
       "\n",
       "        [[ 0.9996962 ],\n",
       "         [ 0.9997451 ],\n",
       "         [ 0.99939144],\n",
       "         [ 0.9992454 ],\n",
       "         [ 0.9991857 ],\n",
       "         [ 0.99915594],\n",
       "         [ 0.99906635],\n",
       "         [ 0.9990687 ],\n",
       "         [ 0.99908173],\n",
       "         [ 0.99913365],\n",
       "         [ 0.99917454],\n",
       "         [ 0.9991355 ],\n",
       "         [ 0.99898475],\n",
       "         [ 0.9988196 ],\n",
       "         [ 0.9988684 ],\n",
       "         [ 0.9990056 ],\n",
       "         [ 0.9990839 ],\n",
       "         [ 0.9991844 ],\n",
       "         [ 0.9992416 ],\n",
       "         [ 0.99930024],\n",
       "         [ 0.999238  ],\n",
       "         [ 0.99917114],\n",
       "         [ 0.99920446],\n",
       "         [ 0.99939775],\n",
       "         [ 0.99904716],\n",
       "         [ 0.9993869 ],\n",
       "         [ 0.99996394],\n",
       "         [ 0.99999756]],\n",
       "\n",
       "        [[ 0.99962723],\n",
       "         [ 0.9995741 ],\n",
       "         [ 0.9989958 ],\n",
       "         [ 0.9989982 ],\n",
       "         [ 0.9989575 ],\n",
       "         [ 0.9989407 ],\n",
       "         [ 0.99881554],\n",
       "         [ 0.9988211 ],\n",
       "         [ 0.99883544],\n",
       "         [ 0.9989094 ],\n",
       "         [ 0.99894595],\n",
       "         [ 0.99890965],\n",
       "         [ 0.9987496 ],\n",
       "         [ 0.9985937 ],\n",
       "         [ 0.9986373 ],\n",
       "         [ 0.9988074 ],\n",
       "         [ 0.9989059 ],\n",
       "         [ 0.99897933],\n",
       "         [ 0.9989811 ],\n",
       "         [ 0.9990066 ],\n",
       "         [ 0.9988853 ],\n",
       "         [ 0.9988165 ],\n",
       "         [ 0.998884  ],\n",
       "         [ 0.9991698 ],\n",
       "         [ 0.9987501 ],\n",
       "         [ 0.9992368 ],\n",
       "         [ 0.9999484 ],\n",
       "         [ 0.99999696]],\n",
       "\n",
       "        [[ 0.9996742 ],\n",
       "         [ 0.99976057],\n",
       "         [ 0.99958545],\n",
       "         [ 0.99960303],\n",
       "         [ 0.9995894 ],\n",
       "         [ 0.9996034 ],\n",
       "         [ 0.9995561 ],\n",
       "         [ 0.99954504],\n",
       "         [ 0.99953383],\n",
       "         [ 0.9995573 ],\n",
       "         [ 0.9995698 ],\n",
       "         [ 0.9995715 ],\n",
       "         [ 0.9995282 ],\n",
       "         [ 0.9994857 ],\n",
       "         [ 0.9994942 ],\n",
       "         [ 0.9995513 ],\n",
       "         [ 0.9995702 ],\n",
       "         [ 0.99956065],\n",
       "         [ 0.99952894],\n",
       "         [ 0.9995263 ],\n",
       "         [ 0.9995102 ],\n",
       "         [ 0.99953824],\n",
       "         [ 0.99960244],\n",
       "         [ 0.9996871 ],\n",
       "         [ 0.99944675],\n",
       "         [ 0.9995815 ],\n",
       "         [ 0.9999213 ],\n",
       "         [ 0.99999297]],\n",
       "\n",
       "        [[ 0.9985324 ],\n",
       "         [ 0.99753606],\n",
       "         [ 0.9982845 ],\n",
       "         [ 0.99842745],\n",
       "         [ 0.99869907],\n",
       "         [ 0.99889016],\n",
       "         [ 0.9988844 ],\n",
       "         [ 0.9989072 ],\n",
       "         [ 0.99887353],\n",
       "         [ 0.998904  ],\n",
       "         [ 0.99889016],\n",
       "         [ 0.9988943 ],\n",
       "         [ 0.9988194 ],\n",
       "         [ 0.9987711 ],\n",
       "         [ 0.99880826],\n",
       "         [ 0.9989042 ],\n",
       "         [ 0.9989289 ],\n",
       "         [ 0.99889505],\n",
       "         [ 0.99884194],\n",
       "         [ 0.9988635 ],\n",
       "         [ 0.99885076],\n",
       "         [ 0.99894774],\n",
       "         [ 0.9991776 ],\n",
       "         [ 0.9993895 ],\n",
       "         [ 0.9992099 ],\n",
       "         [ 0.99931765],\n",
       "         [ 0.9997549 ],\n",
       "         [ 0.9999857 ]],\n",
       "\n",
       "        [[ 0.99969137],\n",
       "         [ 0.99989563],\n",
       "         [ 0.9997693 ],\n",
       "         [ 0.99972355],\n",
       "         [ 0.99980485],\n",
       "         [ 0.9998134 ],\n",
       "         [ 0.9997869 ],\n",
       "         [ 0.9997726 ],\n",
       "         [ 0.9997484 ],\n",
       "         [ 0.9997326 ],\n",
       "         [ 0.9997158 ],\n",
       "         [ 0.9997065 ],\n",
       "         [ 0.9997012 ],\n",
       "         [ 0.99969894],\n",
       "         [ 0.9996937 ],\n",
       "         [ 0.9996882 ],\n",
       "         [ 0.9996784 ],\n",
       "         [ 0.9996784 ],\n",
       "         [ 0.9996977 ],\n",
       "         [ 0.9997364 ],\n",
       "         [ 0.999777  ],\n",
       "         [ 0.99981105],\n",
       "         [ 0.9998581 ],\n",
       "         [ 0.99988   ],\n",
       "         [ 0.999825  ],\n",
       "         [ 0.99990076],\n",
       "         [ 0.99996614],\n",
       "         [ 0.99998915]],\n",
       "\n",
       "        [[ 0.9996327 ],\n",
       "         [ 0.99995667],\n",
       "         [ 0.9999683 ],\n",
       "         [ 0.99997425],\n",
       "         [ 0.9999842 ],\n",
       "         [ 0.99998516],\n",
       "         [ 0.99998504],\n",
       "         [ 0.9999839 ],\n",
       "         [ 0.99998224],\n",
       "         [ 0.9999796 ],\n",
       "         [ 0.9999765 ],\n",
       "         [ 0.9999737 ],\n",
       "         [ 0.9999709 ],\n",
       "         [ 0.9999702 ],\n",
       "         [ 0.9999674 ],\n",
       "         [ 0.99996465],\n",
       "         [ 0.99996406],\n",
       "         [ 0.9999667 ],\n",
       "         [ 0.9999732 ],\n",
       "         [ 0.9999792 ],\n",
       "         [ 0.99998474],\n",
       "         [ 0.99998784],\n",
       "         [ 0.9999892 ],\n",
       "         [ 0.9999872 ],\n",
       "         [ 0.9999369 ],\n",
       "         [ 0.9998593 ],\n",
       "         [ 0.99913436],\n",
       "         [ 0.9998454 ]],\n",
       "\n",
       "        [[ 0.9999488 ],\n",
       "         [ 0.9999835 ],\n",
       "         [ 0.99999464],\n",
       "         [ 0.99999803],\n",
       "         [ 0.9999992 ],\n",
       "         [ 0.9999995 ],\n",
       "         [ 0.9999994 ],\n",
       "         [ 0.99999946],\n",
       "         [ 0.9999993 ],\n",
       "         [ 0.99999905],\n",
       "         [ 0.9999988 ],\n",
       "         [ 0.9999985 ],\n",
       "         [ 0.9999981 ],\n",
       "         [ 0.99999815],\n",
       "         [ 0.999998  ],\n",
       "         [ 0.99999774],\n",
       "         [ 0.9999974 ],\n",
       "         [ 0.9999976 ],\n",
       "         [ 0.99999803],\n",
       "         [ 0.9999984 ],\n",
       "         [ 0.9999989 ],\n",
       "         [ 0.9999992 ],\n",
       "         [ 0.9999994 ],\n",
       "         [ 0.99999946],\n",
       "         [ 0.9999968 ],\n",
       "         [ 0.9999629 ],\n",
       "         [ 0.9999743 ],\n",
       "         [ 0.99995536]]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run tf model\n",
    "\n",
    "fine_tune = slim.assign_from_checkpoint_fn(\n",
    "    checkpoint,\n",
    "    tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES))\n",
    "\n",
    "sess = tf.Session()\n",
    "fine_tune(sess)\n",
    "\n",
    "final_results = sess.run(\n",
    "    result,\n",
    "    feed_dict={z_inp: z, cond_inp: inp},\n",
    ")\n",
    "np.array(final_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9968, 0.9989, 0.9986, 0.9990, 0.9992, 0.9993, 0.9992, 0.9992, 0.9992,\n",
       "        0.9992, 0.9992, 0.9992, 0.9992, 0.9991, 0.9990, 0.9989, 0.9990, 0.9990,\n",
       "        0.9991, 0.9992, 0.9993, 0.9994, 0.9994, 0.9994, 0.9993, 0.9992, 0.9996,\n",
       "        0.9983], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_inp = torch.tensor(inp).transpose(1, 3).transpose(2, 3).float()\n",
    "torch_out = torch_g(torch_inp, torch.tensor(z).float())\n",
    "torch_out[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_image_arr(arr):\n",
    "    arr = np.uint8(arr * 256)\n",
    "    arr = arr.reshape(arr.shape[:-1])\n",
    "    display(Image.fromarray(arr, mode='L').resize((224, 224)))\n",
    "    \n",
    "def render_torch(arr):\n",
    "    arr = np.uint8(arr * 256)\n",
    "    display(Image.fromarray(arr, mode='L').resize((224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=224x224 at 0x7FC42D53A3D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Render tf\n",
    "render_image_arr(np.array(final_results[0][0]) * 0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=224x224 at 0x7FC4165FCBD0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Render torch\n",
    "refined_torch_out = torch_out.detach().numpy() * 0.5 + 0.5\n",
    "\n",
    "render_torch(refined_torch_out[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
