{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import slim\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "import torchvision.transforms as transforms\n",
    "from old_generator import TorchGAN\n",
    "from old_discriminator import TorchDiscriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(\"gdown --id 1TE1Bi5ym-TbLSnlkAAOP0sSQYkgTNl4A --output datasets/omniglot_data.npy\")\n",
    "# os.system(\"mkdir checkpoints\")\n",
    "# os.system(\"gdown --id 1qw_op6L2RebrGik0cBWquDK3RTculrVR --output checkpoints/model.ckpt.data-00000-of-00001\")\n",
    "# os.system(\"gdown --id 17UFRFwWOyJ_-tU72SH0o5mrg2-oEra95 --output checkpoints/model.ckpt.index\")\n",
    "# os.system(\"gdown --id 1iSOAjMUWLDemHljNHk0grCFdblSArBcP --output checkpoints/model.ckpt.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = np.load(\"datasets/omniglot_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_data = raw_data[1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dagan_architectures import UResNetGenerator, Discriminator\n",
    "\n",
    "d = Discriminator(batch_size=1, layer_sizes=[64, 64, 128, 128],\n",
    "                        inner_layers=[5] * 4, name=\"discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1 = tf.placeholder(tf.float32, [1,28,28,1], 'inp1')\n",
    "inp2 = tf.placeholder(tf.float32, [1,28,28,1], 'inp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ashwin/Workspace/DAGAN/dagan_architectures.py:474: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/ashwin/Workspace/DAGAN/dagan_architectures.py:416: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /Library/Python/3.7/site-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /Users/ashwin/Workspace/DAGAN/dagan_architectures.py:453: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /Users/ashwin/Workspace/DAGAN/dagan_architectures.py:527: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /Users/ashwin/Workspace/DAGAN/dagan_architectures.py:529: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /Users/ashwin/Workspace/DAGAN/dagan_architectures.py:535: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/ashwin/Workspace/DAGAN/dagan_architectures.py:535: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "discr layers 22\n",
      "discriminator_parameter_num 7072551\n"
     ]
    }
   ],
   "source": [
    "result = d(inp1, inp2, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_inp = np.ones((1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"checkpoints/checkpoint.ckpt\"\n",
    "ckpt_reader = tf.train.load_checkpoint(checkpoint)\n",
    "def read_tf(var):\n",
    "    return torch.tensor(ckpt_reader.get_tensor(var))\n",
    "\n",
    "def reshape_conv(tensor):\n",
    "    return tensor.transpose(0, 3).transpose(1, 2).transpose(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/checkpoint.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-191.75293]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run tf model\n",
    "\n",
    "fine_tune = slim.assign_from_checkpoint_fn(\n",
    "    checkpoint,\n",
    "    tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES))\n",
    "\n",
    "sess = tf.Session()\n",
    "fine_tune(sess)\n",
    "\n",
    "final_results = sess.run(\n",
    "    result,\n",
    "    feed_dict={inp1: curr_data[0:1], inp2: curr_data[1:2]},\n",
    ")\n",
    "np.array(final_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_d = TorchDiscriminator(28, 1, dropout_rate=0.1)\n",
    "torch_d.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed torch generator weights\n",
    "\n",
    "def convert_conv_layer(torch_layer, conv_path, norm_path=None):\n",
    "    if norm_path is not None:\n",
    "        torch_layer.norm.weight.data = read_tf(norm_path + \"/gamma\").unsqueeze(-1).unsqueeze(-1)\n",
    "        torch_layer.norm.bias.data = read_tf(norm_path + \"/beta\").unsqueeze(-1).unsqueeze(-1)\n",
    "    \n",
    "    torch_layer.conv.weight.data = reshape_conv(read_tf(conv_path + \"/kernel\"))\n",
    "    torch_layer.conv.bias.data = read_tf(conv_path + \"/bias\")\n",
    "    \n",
    "num_layers = torch_d.num_inner_layers\n",
    "\n",
    "# Encoders\n",
    "convert_conv_layer(\n",
    "    torch_d.encode0, \"discriminator/conv_layers/g_conv0/conv2d\", \"discriminator/conv_layers/g_conv0/LayerNorm\")\n",
    "\n",
    "for i in range(1, torch_d.depth):\n",
    "    module = torch_d._modules[\"encode%d\" % i]\n",
    "    convert_conv_layer(\n",
    "        module.pre_conv,\n",
    "        f\"discriminator/conv_layers/g_conv{i}/conv2d\"\n",
    "    )\n",
    "\n",
    "    for j in range(num_layers + 1):\n",
    "        norm_suffix = f\"_{j}\" if j > 0 else \"\"\n",
    "        convert_conv_layer(\n",
    "            module._modules[f\"conv{j}\"],\n",
    "            f\"discriminator/conv_layers/g_conv{i}/conv2d_{j + 1}\",\n",
    "            f\"discriminator/conv_layers/g_conv{i}/LayerNorm{norm_suffix}\",\n",
    "        )\n",
    "\n",
    "torch_d.dense1.weight.data = read_tf(\"discriminator/discriminator_dense_block/dense/kernel\").T\n",
    "torch_d.dense1.bias.data = read_tf(\"discriminator/discriminator_dense_block/dense/bias\").T\n",
    "torch_d.dense2.weight.data = read_tf(\"discriminator/discriminator_out_block/outputs/kernel\").T\n",
    "torch_d.dense2.bias.data = read_tf(\"discriminator/discriminator_out_block/outputs/bias\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_torch(arr):\n",
    "    return torch.tensor(arr).transpose(0, 1).transpose(0, 2).unsqueeze(0)\n",
    "x1 = to_torch(curr_data[0])\n",
    "x2 = to_torch(curr_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch_d(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-191.7530]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_image_arr(arr):\n",
    "    arr = np.uint8(arr * 256)\n",
    "    arr = arr.reshape(arr.shape[:-1])\n",
    "    display(Image.fromarray(arr, mode='L').resize((224, 224)))\n",
    "    \n",
    "def render_torch(arr):\n",
    "    arr = np.uint8(arr * 256)\n",
    "    display(Image.fromarray(arr, mode='L').resize((224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render tf\n",
    "render_image_arr(np.array(final_results[0][0]) * 0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render torch\n",
    "refined_torch_out = torch_out.detach().numpy() * 0.5 + 0.5\n",
    "\n",
    "render_torch(refined_torch_out[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.list_variables(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_tf('discriminator/conv_layers/g_conv0/LayerNorm/beta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = tf.trainable_variables()[-2]\n",
    "var = tf.assign(var, [1., 2., 3.])\n",
    "sess.run(var)\n",
    "# var.eval(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.trainable_variables()[-2].assign([1,2,3],sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
